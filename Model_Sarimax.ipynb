{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6c3965d-d32d-4e93-93b3-097b371b00bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SARIMAX (Temporal Exogenous, Train 2018–2023 → Test 2024)\n",
      "24h (~1 day) → RMSE: 38.72 | MAE: 38.72 | DA: 62.19%\n",
      "48h (~2 day) → RMSE: 43.29 | MAE: 39.80 | DA: 62.19%\n",
      "72h (~3 day) → RMSE: 44.83 | MAE: 39.95 | DA: 62.50%\n",
      "\n",
      "Runtime: 663.58 seconds\n",
      "\n",
      "Saved: Case2_Temporal_AllYears_MultiHorizon_2024.csv\n",
      "        Date  Actual  Predicted_1d  Predicted_2d  Predicted_3d    Error_1d  \\\n",
      "0 2024-01-01   335.0      0.000003      0.000029      0.000030  334.999997   \n",
      "1 2024-01-02   469.0    335.009369      0.000003      0.000003  133.990631   \n",
      "2 2024-01-03   373.0    469.003748    335.009370      0.000003  -96.003748   \n",
      "3 2024-01-04   356.0    372.997315    469.003748    335.009370  -16.997315   \n",
      "4 2024-01-05   387.0    355.999525    372.997315    469.003748   31.000475   \n",
      "5 2024-01-06   345.0    387.000867    355.999525    372.997315  -42.000867   \n",
      "6 2024-01-07   319.0    344.998825    387.000867    355.999525  -25.998825   \n",
      "7 2024-01-08   431.0    653.999206    679.998758    722.000800 -222.999206   \n",
      "8 2024-01-09   387.0    564.993690    787.999132    813.998685 -177.993690   \n",
      "9 2024-01-10   347.0    290.995051    468.993719    691.999162   56.004949   \n",
      "\n",
      "     Error_2d    Error_3d  \n",
      "0  334.999971  334.999970  \n",
      "1  468.999997  468.999997  \n",
      "2   37.990630  372.999997  \n",
      "3 -113.003748   20.990630  \n",
      "4   14.002685  -82.003748  \n",
      "5  -10.999525  -27.997315  \n",
      "6  -68.000867  -36.999525  \n",
      "7 -248.998758 -291.000800  \n",
      "8 -400.999132 -426.998685  \n",
      "9 -121.993719 -344.999162  \n",
      "          Date  Actual  Predicted_1d  Predicted_2d  Predicted_3d   Error_1d  \\\n",
      "356 2024-12-22   329.0    345.999809    352.999383    375.000506 -16.999809   \n",
      "357 2024-12-23   469.0    469.999518    486.999802    493.999377  -0.999518   \n",
      "358 2024-12-24   400.0    399.999971    400.999517    417.999801   0.000029   \n",
      "359 2024-12-25   361.0    400.999962    400.999933    401.999479 -39.999962   \n",
      "360 2024-12-26   426.0    360.998908    400.999989    400.999960  65.001092   \n",
      "361 2024-12-27   424.0    425.001825    359.998915    399.999996  -1.001825   \n",
      "362 2024-12-28   357.0    352.999974    354.001827    288.998917   4.000026   \n",
      "363 2024-12-29   313.0    347.000117    342.999979    344.001832 -34.000117   \n",
      "364 2024-12-30   455.0    452.999049    487.000117    482.999980   2.000951   \n",
      "365 2024-12-31   383.0    386.000056    383.999049    418.000117  -3.000056   \n",
      "\n",
      "      Error_2d   Error_3d  \n",
      "356 -23.999383 -46.000506  \n",
      "357 -17.999802 -24.999377  \n",
      "358  -0.999517 -17.999801  \n",
      "359 -39.999933 -40.999479  \n",
      "360  25.000011  25.000040  \n",
      "361  64.001085  24.000004  \n",
      "362   2.998173  68.001083  \n",
      "363 -29.999979 -31.001832  \n",
      "364 -32.000117 -27.999980  \n",
      "365  -0.999049 -35.000117  \n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# CASE 2 (ALL YEARS, FIXED): Temporal Exogenous\n",
    "# Train: 2018-01-01 .. 2023-12-31\n",
    "# Test : 2024-01-01 .. 2024-12-31\n",
    "# ===============================\n",
    "\n",
    "CSV_PATH = \"AnE_Data_fin.csv\"           # 2018–2024 raw CSV (12-hour clock)\n",
    "XLSX_2024_PATH = \"ANE_Data_2024.xlsx\"   # trusted 2024 file\n",
    "CAL_PATH = \"calendar_2018_2024.csv\"     # calendar with holiday info\n",
    "\n",
    "HOURS = [24, 48, 72]\n",
    "HORIZON_DAYS = [1, 2, 3]\n",
    "m = 7  # weekly seasonality for daily data\n",
    "\n",
    "# ---------- 1) ARRIVALS: 2018–2023 from CSV, 2024 from Excel ----------\n",
    "def load_daily_from_csv(csv_path, start=\"2018-01-01\", end=\"2023-12-31\"):\n",
    "    df = pd.read_csv(csv_path, low_memory=False)\n",
    "    # robust parse for strings like \"1/1/2018  12:13:00 am\"\n",
    "    # first try exact format; if it fails for some rows, fall back with errors='coerce'\n",
    "    try:\n",
    "        dt = pd.to_datetime(df[\"A&E Admit Date Time\"],\n",
    "                            format=\"%m/%d/%Y %I:%M:%S %p\",\n",
    "                            errors=\"coerce\")\n",
    "    except Exception:\n",
    "        dt = pd.to_datetime(df[\"A&E Admit Date Time\"], errors=\"coerce\")\n",
    "    df = df.assign(dt=dt).dropna(subset=[\"dt\"])\n",
    "    df = df[(df[\"dt\"] >= pd.Timestamp(start)) & (df[\"dt\"] <= pd.Timestamp(end))].copy()\n",
    "\n",
    "    # daily counts on a full grid to avoid gaps\n",
    "    full_index = pd.date_range(start, end, freq=\"D\")\n",
    "    daily_counts = df.groupby(df[\"dt\"].dt.date).size()\n",
    "    arrivals = daily_counts.reindex(full_index.date, fill_value=0).astype(float)\n",
    "    return pd.Series(arrivals.values, index=full_index, name=\"Arrivals\")\n",
    "\n",
    "def load_daily_2024_from_excel(xlsx_path):\n",
    "    raw = pd.read_excel(xlsx_path)\n",
    "    raw[\"A&E Admit Date Time\"] = pd.to_datetime(raw[\"A&E Admit Date Time\"], errors=\"coerce\")\n",
    "    raw = raw.dropna(subset=[\"A&E Admit Date Time\"])\n",
    "    full_index = pd.date_range(\"2024-01-01\", \"2024-12-31\", freq=\"D\")\n",
    "    daily_counts = raw.groupby(raw[\"A&E Admit Date Time\"].dt.date).size()\n",
    "    arrivals = daily_counts.reindex(full_index.date, fill_value=0).astype(float)\n",
    "    return pd.Series(arrivals.values, index=full_index, name=\"Arrivals\")\n",
    "\n",
    "y_2018_2023 = load_daily_from_csv(CSV_PATH, \"2018-01-01\", \"2023-12-31\")\n",
    "y_2024       = load_daily_2024_from_excel(XLSX_2024_PATH)\n",
    "\n",
    "# concatenate into one continuous series 2018–2024\n",
    "y_all = pd.concat([y_2018_2023, y_2024])\n",
    "y_all.index.name = \"Date\"\n",
    "\n",
    "df = y_all.to_frame()\n",
    "\n",
    "# ---------- 2) TEMPORAL EXOG (DoW, Quarter, DoM_norm, Holiday) ----------\n",
    "cal = pd.read_csv(CAL_PATH)\n",
    "\n",
    "date_col_candidates = [c for c in cal.columns if c.lower() in (\"date\", \"ds\")]\n",
    "if not date_col_candidates:\n",
    "    raise ValueError(\"calendar_2018_2024.csv must have a 'Date' (or 'ds') column.\")\n",
    "cal = cal.rename(columns={date_col_candidates[0]: \"Date\"})\n",
    "cal[\"Date\"] = pd.to_datetime(cal[\"Date\"], errors=\"coerce\")\n",
    "cal = cal.dropna(subset=[\"Date\"]).sort_values(\"Date\").set_index(\"Date\")\n",
    "\n",
    "# detect a holiday flag and normalize to 0/1\n",
    "hol_cols = [c for c in cal.columns if (\"holiday\" in c.lower()) or (\"public\" in c.lower())]\n",
    "if not hol_cols:\n",
    "    cal[\"is_holiday\"] = 0\n",
    "    hol_col = \"is_holiday\"\n",
    "else:\n",
    "    hol_col = hol_cols[0]\n",
    "    cal[hol_col] = (\n",
    "        cal[hol_col].astype(str).str.strip().str.lower()\n",
    "        .map({\"1\":1,\"true\":1,\"yes\":1,\"y\":1,\"t\":1,\"holiday\":1})\n",
    "        .fillna(0).astype(int)\n",
    "    )\n",
    "\n",
    "full_index = pd.date_range(\"2018-01-01\", \"2024-12-31\", freq=\"D\")\n",
    "cal_full = cal.reindex(full_index).copy()\n",
    "cal_full.index.name = \"Date\"\n",
    "cal_full[hol_col] = cal_full[hol_col].fillna(0).astype(int)\n",
    "\n",
    "tmp = pd.DataFrame(index=full_index)\n",
    "tmp[\"dow\"] = tmp.index.dayofweek\n",
    "tmp[\"dom\"] = tmp.index.day\n",
    "tmp[\"qtr\"] = tmp.index.quarter\n",
    "tmp[\"holiday\"] = cal_full[hol_col].values\n",
    "tmp[\"dom_norm\"] = (tmp[\"dom\"] - tmp[\"dom\"].mean()) / (tmp[\"dom\"].std() + 1e-8)\n",
    "\n",
    "dow_dummies = pd.get_dummies(tmp[\"dow\"], prefix=\"dow\", drop_first=True)\n",
    "qtr_dummies = pd.get_dummies(tmp[\"qtr\"], prefix=\"qtr\", drop_first=True)\n",
    "exog_full = pd.concat([dow_dummies, qtr_dummies, tmp[[\"dom_norm\", \"holiday\"]]], axis=1)\n",
    "\n",
    "# numeric hardening; align to df\n",
    "exog_full = exog_full.apply(pd.to_numeric, errors=\"coerce\")\n",
    "exog_full = exog_full.replace([np.inf, -np.inf], np.nan).fillna(0.0).astype(\"float64\")\n",
    "exog_full = exog_full.reindex(df.index)\n",
    "\n",
    "# ---------- 3) TRAIN / TEST SPLIT ----------\n",
    "train_end = pd.Timestamp(\"2023-12-31\")\n",
    "train = df.loc[:train_end]\n",
    "test  = df.loc[\"2024-01-01\":\"2024-12-31\"]\n",
    "\n",
    "y_train = train[\"Arrivals\"].values.astype(float)\n",
    "y_test  = test[\"Arrivals\"].values.astype(float)\n",
    "train_exog = exog_full.loc[train.index]\n",
    "test_exog  = exog_full.loc[test.index]\n",
    "test_index = test.index\n",
    "\n",
    "# ---------- 4) FIT SARIMAX (reuse params via filter) ----------\n",
    "base_exog = SARIMAX(\n",
    "    y_train,\n",
    "    exog=train_exog.values,\n",
    "    order=(1, 1, 1),\n",
    "    seasonal_order=(1, 1, 1, m),\n",
    "    enforce_stationarity=False,\n",
    "    enforce_invertibility=False\n",
    ").fit(disp=False)\n",
    "params_exog = base_exog.params\n",
    "\n",
    "def forecast_with_filter_exog(history_y, history_exog, steps, future_exog):\n",
    "    mod = SARIMAX(\n",
    "        history_y,\n",
    "        exog=history_exog,\n",
    "        order=(1, 1, 1),\n",
    "        seasonal_order=(1, 1, 1, m),\n",
    "        enforce_stationarity=False,\n",
    "        enforce_invertibility=False\n",
    "    )\n",
    "    res_filt = mod.filter(params_exog)\n",
    "    yhat = np.asarray(res_filt.get_forecast(steps=steps, exog=future_exog).predicted_mean, dtype=float)\n",
    "    return np.abs(yhat)  # keep absolute as required\n",
    "\n",
    "def da_window(y_true_vec, y_pred_vec):\n",
    "    yt, yp = np.asarray(y_true_vec, float), np.asarray(y_pred_vec, float)\n",
    "    if len(yt) < 2 or len(yp) < 2:\n",
    "        return np.nan\n",
    "    return (np.sign(np.diff(yt)) == np.sign(np.diff(yp))).mean() * 100.0\n",
    "\n",
    "# ---------- 5) SLIDING-WINDOW EVAL ON 2024 (with 24h DA fix) ----------\n",
    "results_exog = {h: {\"rmse\": [], \"mae\": [], \"da\": []} for h in HORIZON_DAYS}\n",
    "t0 = time.time()\n",
    "\n",
    "for h in HORIZON_DAYS:\n",
    "    if h == 1:\n",
    "        for i in range(0, len(y_test) - 1 + 1):\n",
    "            hist_y  = np.r_[y_train, y_test[:i]]\n",
    "            hist_ex = np.vstack([train_exog.values, test_exog.values[:i]]) if i > 0 else train_exog.values\n",
    "            fut_ex  = test_exog.values[i:i+1]\n",
    "\n",
    "            y_pred1 = forecast_with_filter_exog(hist_y, hist_ex, 1, fut_ex)[0]\n",
    "            y_true1 = y_test[i]\n",
    "\n",
    "            results_exog[h][\"rmse\"].append(np.sqrt(mean_squared_error([y_true1], [y_pred1])))\n",
    "            results_exog[h][\"mae\"].append(mean_absolute_error([y_true1], [y_pred1]))\n",
    "\n",
    "            if i >= 1:  # DA fix: compare to previous actual\n",
    "                prev_actual = y_test[i-1]\n",
    "                dir_true = np.sign(y_true1 - prev_actual)\n",
    "                dir_pred = np.sign(y_pred1 - prev_actual)\n",
    "                results_exog[h][\"da\"].append(100.0 if dir_true == dir_pred else 0.0)\n",
    "            if i % 100 == 0: gc.collect()\n",
    "    else:\n",
    "        for i in range(0, len(y_test) - h + 1):\n",
    "            hist_y  = np.r_[y_train, y_test[:i]]\n",
    "            hist_ex = np.vstack([train_exog.values, test_exog.values[:i]]) if i > 0 else train_exog.values\n",
    "            fut_ex  = test_exog.values[i:i+h]\n",
    "\n",
    "            y_predh = forecast_with_filter_exog(hist_y, hist_ex, h, fut_ex)\n",
    "            y_trueh = y_test[i:i+h]\n",
    "\n",
    "            results_exog[h][\"rmse\"].append(np.sqrt(mean_squared_error(y_trueh, y_predh)))\n",
    "            results_exog[h][\"mae\"].append(mean_absolute_error(y_trueh, y_predh))\n",
    "            results_exog[h][\"da\"].append(da_window(y_trueh, y_predh))\n",
    "            if i % 100 == 0: gc.collect()\n",
    "\n",
    "elapsed = time.time() - t0\n",
    "print(\"\\nSARIMAX (Temporal Exogenous, Train 2018–2023 → Test 2024)\")\n",
    "for hrs, h in zip(HOURS, HORIZON_DAYS):\n",
    "    out = {metric: (np.nan if len(results_exog[h][metric]) == 0 else np.nanmean(results_exog[h][metric]))\n",
    "           for metric in results_exog[h]}\n",
    "    print(f\"{hrs}h (~{h} day) → RMSE: {out['rmse']:.2f} | MAE: {out['mae']:.2f} | DA: {out['da']:.2f}%\")\n",
    "print(f\"\\nRuntime: {elapsed:.2f} seconds\")\n",
    "\n",
    "# ---------- 6) MULTI-HORIZON PREDICTIONS TABLE (target-aligned, pre-fill & year-end safe) ----------\n",
    "n_test = len(y_test)\n",
    "preds_by_h = {h: np.full(n_test, np.nan, dtype=float) for h in HORIZON_DAYS}\n",
    "max_h = max(HORIZON_DAYS)\n",
    "\n",
    "# pre-fill first 1–2 targets using pre-2024 origins\n",
    "for offset in range(1, max_h):\n",
    "    origin_len = len(y_train) - offset\n",
    "    if origin_len <= 0:\n",
    "        continue\n",
    "    hist_y  = y_train[:origin_len]\n",
    "    hist_ex = train_exog.values[:origin_len]\n",
    "    pre_hat = forecast_with_filter_exog(hist_y, hist_ex, max_h, test_exog.values[:max_h])\n",
    "    for h in HORIZON_DAYS:\n",
    "        target_idx = h - 1 - offset\n",
    "        if 0 <= target_idx < n_test:\n",
    "            preds_by_h[h][target_idx] = pre_hat[h - 1]\n",
    "\n",
    "# rolling through 2024 — \n",
    "for i in range(n_test):\n",
    "    hist_y  = np.r_[y_train, y_test[:i]]\n",
    "    hist_ex = np.vstack([train_exog.values, test_exog.values[:i]]) if i > 0 else train_exog.values\n",
    "    for h in HORIZON_DAYS:\n",
    "        target_idx = i + h - 1\n",
    "        if 0 <= target_idx < n_test:\n",
    "            fut_ex = test_exog.values[i:i+h]\n",
    "            yhat_h = forecast_with_filter_exog(hist_y, hist_ex, h, fut_ex)\n",
    "            preds_by_h[h][target_idx] = yhat_h[h - 1]\n",
    "\n",
    "out = pd.DataFrame({\"Date\": test_index, \"Actual\": y_test})\n",
    "out[\"Predicted_1d\"] = preds_by_h[1]\n",
    "out[\"Predicted_2d\"] = preds_by_h[2]\n",
    "out[\"Predicted_3d\"] = preds_by_h[3]\n",
    "out[\"Error_1d\"] = out[\"Actual\"] - out[\"Predicted_1d\"]\n",
    "out[\"Error_2d\"] = out[\"Actual\"] - out[\"Predicted_2d\"]\n",
    "out[\"Error_3d\"] = out[\"Actual\"] - out[\"Predicted_3d\"]\n",
    "\n",
    "out.to_csv(\"Case2_Temporal_AllYears_MultiHorizon_2024.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"\\nSaved: Case2_Temporal_AllYears_MultiHorizon_2024.csv\")\n",
    "print(out.head(10))\n",
    "print(out.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41752159-2d3f-4a36-9a29-2575d4278f3e",
   "metadata": {},
   "source": [
    "# <font color= maroon>  Base Model (prediction for 24, 48 and 72 hours) 2022 TO 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833c4748-9fa0-4fc0-aef4-ba8435bfd524",
   "metadata": {},
   "source": [
    "# <font color= maroon>  Model with Temporal Data (prediction for 24, 48 and 72 hours) 2022 TO 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23c60241-c441-4b5b-8d4e-884284eec8cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SARIMAX (Temporal Exogenous, REFIT each origin) — Train 2022–2023 → Test 2024\n",
      "24h (~1 day) → RMSE 19.59 | MAE 19.59 | MAPE 5.17% | DA 80.55%\n",
      "48h (~2 day) → RMSE 21.82 | MAE 19.48 | MAPE 5.14% | DA 73.97%\n",
      "72h (~3 day) → RMSE 22.61 | MAE 19.48 | MAPE 5.14% | DA 73.90%\n",
      "\n",
      "Runtime: 8137.23 seconds\n",
      "\n",
      "Saved: Case2_Temporal_MultiHorizon_Predictions_Daily_2022to2024_23.csv\n",
      "        Date  Actual  Predicted_1d  Predicted_2d  Predicted_3d   Error_1d  \\\n",
      "0 2024-01-01   335.0    406.683057    451.306765    445.829353 -71.683057   \n",
      "1 2024-01-02   469.0    377.671344    401.544759    407.659149  91.328656   \n",
      "2 2024-01-03   373.0    393.293925    371.085240    390.742321 -20.293925   \n",
      "3 2024-01-04   356.0    380.075178    382.662323    366.196275 -24.075178   \n",
      "4 2024-01-05   387.0    368.890369    372.586829    373.761618  18.109631   \n",
      "5 2024-01-06   345.0    343.570101    341.512010    344.193588   1.429899   \n",
      "6 2024-01-07   319.0    346.347269    347.501683    346.808122 -27.347269   \n",
      "7 2024-01-08   431.0    429.621713    433.673407    436.134942   1.378287   \n",
      "8 2024-01-09   387.0    392.371843    392.153728    399.258891  -5.371843   \n",
      "9 2024-01-10   347.0    375.757060    376.624687    378.395440 -28.757060   \n",
      "\n",
      "     Error_2d    Error_3d  \n",
      "0 -116.306765 -110.829353  \n",
      "1   67.455241   61.340851  \n",
      "2    1.914760  -17.742321  \n",
      "3  -26.662323  -10.196275  \n",
      "4   14.413171   13.238382  \n",
      "5    3.487990    0.806412  \n",
      "6  -28.501683  -27.808122  \n",
      "7   -2.673407   -5.134942  \n",
      "8   -5.153728  -12.258891  \n",
      "9  -29.624687  -31.395440  \n",
      "          Date  Actual  Predicted_1d  Predicted_2d  Predicted_3d   Error_1d  \\\n",
      "356 2024-12-22   329.0    355.786196    358.986043    356.385772 -26.786196   \n",
      "357 2024-12-23   469.0    455.309848    461.215241    462.425607  13.690152   \n",
      "358 2024-12-24   400.0    414.408186    411.565173    416.206584 -14.408186   \n",
      "359 2024-12-25   361.0    357.646269    360.426845    358.342787   3.353731   \n",
      "360 2024-12-26   426.0    393.391322    392.666492    394.653356  32.608678   \n",
      "361 2024-12-27   424.0    398.295269    392.034582    391.402053  25.704731   \n",
      "362 2024-12-28   357.0    356.653240    351.262508    347.269131   0.346760   \n",
      "363 2024-12-29   313.0    359.453142    359.685859    355.831300 -46.453142   \n",
      "364 2024-12-30   455.0    455.782204    465.770673    465.052573  -0.782204   \n",
      "365 2024-12-31   383.0    412.329511    412.637642    419.827894 -29.329511   \n",
      "\n",
      "      Error_2d   Error_3d  \n",
      "356 -29.986043 -27.385772  \n",
      "357   7.784759   6.574393  \n",
      "358 -11.565173 -16.206584  \n",
      "359   0.573155   2.657213  \n",
      "360  33.333508  31.346644  \n",
      "361  31.965418  32.597947  \n",
      "362   5.737492   9.730869  \n",
      "363 -46.685859 -42.831300  \n",
      "364 -10.770673 -10.052573  \n",
      "365 -29.637642 -36.827894  \n"
     ]
    }
   ],
   "source": [
    "# CASE 2 (Temporal Exogenous) — Train: 2022–2023, Test: 2024\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, gc, warnings\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.simplefilter(\"ignore\", ConvergenceWarning)\n",
    "\n",
    "# Config\n",
    "CSV_PATH = \"AnE_Data_fin.csv\"           # 2018–2024 raw CSV\n",
    "CAL_PATH = \"calendar_2018_2024.csv\"     # calendar with holiday info\n",
    "\n",
    "HOURS = [24, 48, 72]\n",
    "HORIZON_DAYS = [1, 2, 3]\n",
    "m = 7  # weekly seasonality (daily)\n",
    "\n",
    "# Robust datetime parsing for CSV\n",
    "def _try_parse(series, fmt=None, dayfirst=False):\n",
    "    return pd.to_datetime(series, format=fmt, errors=\"coerce\", dayfirst=dayfirst)\n",
    "\n",
    "def _parse_admit_dt_multi(df):\n",
    "    s = df[\"A&E Admit Date Time\"]\n",
    "    dt = pd.Series(pd.NaT, index=df.index, dtype=\"datetime64[ns]\")\n",
    "\n",
    "    # US 12h with/without seconds\n",
    "    cand = _try_parse(s, \"%m/%d/%Y %I:%M:%S %p\", dayfirst=False); dt = dt.fillna(cand)\n",
    "    cand = _try_parse(s, \"%m/%d/%Y %I:%M %p\",   dayfirst=False); dt = dt.fillna(cand)\n",
    "\n",
    "    # DD/MM 24h with/without seconds\n",
    "    cand = _try_parse(s, \"%d/%m/%Y %H:%M:%S\",   dayfirst=True);  dt = dt.fillna(cand)\n",
    "    cand = _try_parse(s, \"%d/%m/%Y %H:%M\",      dayfirst=True);  dt = dt.fillna(cand)\n",
    "\n",
    "    # Last-resort inference\n",
    "    cand = pd.to_datetime(s, errors=\"coerce\", dayfirst=True,  infer_datetime_format=True);  dt = dt.fillna(cand)\n",
    "    cand = pd.to_datetime(s, errors=\"coerce\", dayfirst=False, infer_datetime_format=True);  dt = dt.fillna(cand)\n",
    "\n",
    "    # Fallback to date-only column (safe for daily aggregation)\n",
    "    if \"A&E Admit Date\" in df.columns:\n",
    "        d_only = pd.to_datetime(df[\"A&E Admit Date\"], errors=\"coerce\", dayfirst=True)\n",
    "        dt = dt.where(dt.notna(), d_only)\n",
    "\n",
    "    return dt\n",
    "\n",
    "# ARRIVALS: 2022–2023 and 2024 from CSV \n",
    "def load_daily_from_csv_range(csv_path, start=\"2022-01-01\", end=\"2023-12-31\"):\n",
    "    df = pd.read_csv(csv_path, low_memory=False)\n",
    "\n",
    "    # Parse datetimes with the multi-format helper\n",
    "    dt = _parse_admit_dt_multi(df)\n",
    "    df = df.assign(dt=dt).dropna(subset=[\"dt\"])\n",
    "\n",
    "    # Normalize to midnight (Timestamp), avoid Python datetime.date\n",
    "    df[\"day\"] = pd.to_datetime(df[\"dt\"], errors=\"coerce\").dt.floor(\"D\")\n",
    "    df = df.dropna(subset=[\"day\"])\n",
    "\n",
    "    # Filter by requested range using the normalized day\n",
    "    start_ts = pd.Timestamp(start)\n",
    "    end_ts   = pd.Timestamp(end)\n",
    "    df = df[(df[\"day\"] >= start_ts) & (df[\"day\"] <= end_ts)].copy()\n",
    "\n",
    "    # Aggregate safely to daily counts\n",
    "    daily_counts = df.groupby(\"day\", sort=True).size()\n",
    "\n",
    "    # Continuous daily index for the window (tz-naive)\n",
    "    full_index = pd.date_range(start=start_ts, end=end_ts, freq=\"D\")\n",
    "\n",
    "    # Align & fill missing days with 0\n",
    "    s = daily_counts.reindex(full_index, fill_value=0).astype(float)\n",
    "    s.index.name = \"Date\"\n",
    "    s.name = \"Arrivals\"\n",
    "\n",
    "    if s.sum() == 0:\n",
    "        raise ValueError(f\"CSV arrivals sum to 0 in {start}..{end}. Parsing likely failed.\")\n",
    "    return s\n",
    "\n",
    "y_2022_2023 = load_daily_from_csv_range(CSV_PATH, \"2022-01-01\", \"2023-12-31\")\n",
    "y_2024       = load_daily_from_csv_range(CSV_PATH, \"2024-01-01\", \"2024-12-31\")\n",
    "\n",
    "# Merge series\n",
    "y_all = pd.concat([y_2022_2023, y_2024])\n",
    "y_all.index.name = \"Date\"\n",
    "df = y_all.to_frame()\n",
    "\n",
    "# TEMPORAL EXOG\n",
    "cal = pd.read_csv(CAL_PATH)\n",
    "\n",
    "# accept 'Date' or 'ds'\n",
    "date_col_candidates = [c for c in cal.columns if c.lower() in (\"date\", \"ds\")]\n",
    "if not date_col_candidates:\n",
    "    raise ValueError(\"calendar_2018_2024.csv must have a 'Date' (or 'ds') column.\")\n",
    "cal = cal.rename(columns={date_col_candidates[0]: \"Date\"})\n",
    "cal[\"Date\"] = pd.to_datetime(cal[\"Date\"], errors=\"coerce\")\n",
    "cal = cal.dropna(subset=[\"Date\"]).sort_values(\"Date\").set_index(\"Date\")\n",
    "\n",
    "# use first holiday-like column if present, else create one\n",
    "hol_cols = [c for c in cal.columns if (\"holiday\" in c.lower()) or (\"public\" in c.lower())]\n",
    "if not hol_cols:\n",
    "    cal[\"is_holiday\"] = 0\n",
    "    hol_col = \"is_holiday\"\n",
    "else:\n",
    "    hol_col = hol_cols[0]\n",
    "    cal[hol_col] = (\n",
    "        cal[hol_col]\n",
    "        .astype(str).str.strip().str.lower()\n",
    "        .map({\"1\":1,\"true\":1,\"yes\":1,\"y\":1,\"t\":1,\"holiday\":1})\n",
    "        .fillna(0).astype(int)\n",
    "    )\n",
    "\n",
    "full_index = pd.date_range(\"2022-01-01\", \"2024-12-31\", freq=\"D\")\n",
    "cal_full = cal.reindex(full_index).copy()\n",
    "cal_full.index.name = \"Date\"\n",
    "cal_full[hol_col] = cal_full[hol_col].fillna(0).astype(int)\n",
    "\n",
    "tmp = pd.DataFrame(index=full_index)\n",
    "tmp[\"dow\"] = tmp.index.dayofweek          # 0=Mon\n",
    "tmp[\"dom\"] = tmp.index.day\n",
    "tmp[\"qtr\"] = tmp.index.quarter\n",
    "tmp[\"holiday\"] = cal_full[hol_col].values\n",
    "tmp[\"dom_norm\"] = (tmp[\"dom\"] - tmp[\"dom\"].mean()) / (tmp[\"dom\"].std() + 1e-8)\n",
    "\n",
    "dow_dummies = pd.get_dummies(tmp[\"dow\"], prefix=\"dow\", drop_first=True)\n",
    "qtr_dummies = pd.get_dummies(tmp[\"qtr\"], prefix=\"qtr\", drop_first=True)\n",
    "\n",
    "exog_full = pd.concat([dow_dummies, qtr_dummies, tmp[[\"dom_norm\", \"holiday\"]]], axis=1)\n",
    "exog_full = (\n",
    "    exog_full.apply(pd.to_numeric, errors=\"coerce\")\n",
    "    .replace([np.inf, -np.inf], np.nan)\n",
    "    .fillna(0.0)\n",
    "    .astype(\"float64\")\n",
    ")\n",
    "exog_full = exog_full.reindex(df.index)\n",
    "\n",
    "# TRAIN / TEST SPLIT \n",
    "train = df.loc[\"2022-01-01\":\"2023-12-31\"]\n",
    "test  = df.loc[\"2024-01-01\":\"2024-12-31\"]\n",
    "\n",
    "y_train = train[\"Arrivals\"].values.astype(float)\n",
    "y_test  = test[\"Arrivals\"].values.astype(float)\n",
    "train_exog = exog_full.loc[train.index]\n",
    "test_exog  = exog_full.loc[test.index]\n",
    "test_index = test.index\n",
    "\n",
    "if np.all(y_train == 0) or np.all(y_test == 0):\n",
    "    raise ValueError(\"Train or test arrivals are all zeros. Check inputs.\")\n",
    "\n",
    "# Utility metrics\n",
    "def da_window(y_true_vec, y_pred_vec):\n",
    "    yt, yp = np.asarray(y_true_vec, float), np.asarray(y_pred_vec, float)\n",
    "    if len(yt) < 2 or len(yp) < 2:\n",
    "        return np.nan\n",
    "    return (np.sign(np.diff(yt)) == np.sign(np.diff(yp))).mean() * 100.0\n",
    "\n",
    "# MAPE helper \n",
    "def mape_percent(y_true_vec, y_pred_vec):\n",
    "    yt, yp = np.asarray(y_true_vec, float), np.asarray(y_pred_vec, float)\n",
    "    mask = yt != 0\n",
    "    if mask.sum() == 0:\n",
    "        return np.nan\n",
    "    return np.mean(np.abs((yt[mask] - yp[mask]) / yt[mask])) * 100.0\n",
    "\n",
    "# Re-fitting forecaster \n",
    "def refit_and_forecast_exog(history_y, history_exog, steps, future_exog):\n",
    "\n",
    "    model = SARIMAX(\n",
    "        history_y,\n",
    "        exog=history_exog,\n",
    "        order=(1, 1, 1),\n",
    "        seasonal_order=(1, 1, 1, m),\n",
    "        enforce_stationarity=False,\n",
    "        enforce_invertibility=False\n",
    "    )\n",
    "    res = model.fit(disp=False)\n",
    "    yhat = np.asarray(res.get_forecast(steps=steps, exog=future_exog).predicted_mean, dtype=float)\n",
    "    return np.clip(yhat, 0.0, None)\n",
    "\n",
    "# EVAL \n",
    "results_exog = {h: {\"rmse\": [], \"mae\": [], \"mape\": [], \"da\": []} for h in HORIZON_DAYS}\n",
    "t0 = time.time()\n",
    "\n",
    "for h in HORIZON_DAYS:\n",
    "    if h == 1:\n",
    "        # 1-day: direction vs previous actual\n",
    "        for i in range(0, len(y_test)):\n",
    "            hist_y  = np.r_[y_train, y_test[:i]]\n",
    "            hist_ex = (np.vstack([train_exog.values, test_exog.values[:i]]) if i > 0 else train_exog.values)\n",
    "            fut_ex  = test_exog.values[i:i+1]\n",
    "\n",
    "            y_pred1 = refit_and_forecast_exog(hist_y, hist_ex, 1, fut_ex)[0]\n",
    "            y_true1 = y_test[i]\n",
    "\n",
    "            results_exog[h][\"rmse\"].append(np.sqrt(mean_squared_error([y_true1], [y_pred1])))\n",
    "            results_exog[h][\"mae\"].append(mean_absolute_error([y_true1], [y_pred1]))\n",
    "            results_exog[h][\"mape\"].append(mape_percent([y_true1], [y_pred1]))\n",
    "            if i >= 1:\n",
    "                prev_actual = y_test[i-1]\n",
    "                dir_true = np.sign(y_true1 - prev_actual)\n",
    "                dir_pred = np.sign(y_pred1 - prev_actual)\n",
    "                results_exog[h][\"da\"].append(100.0 if dir_true == dir_pred else 0.0)\n",
    "\n",
    "            if i % 30 == 0: gc.collect()\n",
    "    else:\n",
    "        # 2d/3d: window DA over the h-length path\n",
    "        for i in range(0, len(y_test) - h + 1):\n",
    "            hist_y  = np.r_[y_train, y_test[:i]]\n",
    "            hist_ex = (np.vstack([train_exog.values, test_exog.values[:i]]) if i > 0 else train_exog.values)\n",
    "            fut_ex  = test_exog.values[i:i+h]\n",
    "\n",
    "            y_predh = refit_and_forecast_exog(hist_y, hist_ex, h, fut_ex)\n",
    "            y_trueh = y_test[i:i+h]\n",
    "\n",
    "            results_exog[h][\"rmse\"].append(np.sqrt(mean_squared_error(y_trueh, y_predh)))\n",
    "            results_exog[h][\"mae\"].append(mean_absolute_error(y_trueh, y_predh))\n",
    "            results_exog[h][\"mape\"].append(mape_percent(y_trueh, y_predh))\n",
    "            results_exog[h][\"da\"].append(da_window(y_trueh, y_predh))\n",
    "\n",
    "            if i % 30 == 0: gc.collect()\n",
    "\n",
    "elapsed = time.time() - t0\n",
    "print(\"\\nSARIMAX (Temporal Exogenous, REFIT each origin) — Train 2022–2023 → Test 2024\")\n",
    "for hrs, h in zip(HOURS, HORIZON_DAYS):\n",
    "    out = {metric: (np.nan if len(results_exog[h][metric]) == 0 else np.nanmean(results_exog[h][metric]))\n",
    "           for metric in results_exog[h]}\n",
    "    print(f\"{hrs}h (~{h} day) → RMSE {out['rmse']:.2f} | MAE {out['mae']:.2f} | MAPE {out['mape']:.2f}% | DA {out['da']:.2f}%\")\n",
    "print(f\"\\nRuntime: {elapsed:.2f} seconds\")\n",
    "\n",
    "# MULTI-HORIZON TABLE (target-aligned; pre-fill & year-end safe) \n",
    "n_test = len(y_test)\n",
    "preds_by_h = {h: np.full(n_test, np.nan, dtype=float) for h in HORIZON_DAYS}\n",
    "max_h = max(HORIZON_DAYS)\n",
    "\n",
    "# Pre-fill first 1–2 targets using pre-2024 origins (refit once per offset)\n",
    "for offset in range(1, max_h):  # 1 and 2\n",
    "    origin_len = len(y_train) - offset\n",
    "    if origin_len <= 0:\n",
    "        continue\n",
    "    hist_y  = y_train[:origin_len]\n",
    "    hist_ex = train_exog.values[:origin_len]\n",
    "    fut_ex_full = test_exog.values[:max_h]  # future exog slices for Jan 1..3\n",
    "    pre_hat = refit_and_forecast_exog(hist_y, hist_ex, max_h, fut_ex_full)\n",
    "    for h in HORIZON_DAYS:\n",
    "        target_idx = h - 1 - offset\n",
    "        if 0 <= target_idx < n_test:\n",
    "            preds_by_h[h][target_idx] = pre_hat[h - 1]\n",
    "\n",
    "# Rolling through 2024 — only fill valid targets (refit at each i)\n",
    "for i in range(n_test):\n",
    "    hist_y  = np.r_[y_train, y_test[:i]]\n",
    "    hist_ex = (np.vstack([train_exog.values, test_exog.values[:i]]) if i > 0 else train_exog.values)\n",
    "    for h in HORIZON_DAYS:\n",
    "        target_idx = i + h - 1\n",
    "        if 0 <= target_idx < n_test:\n",
    "            fut_ex = test_exog.values[i:i+h]\n",
    "            yhat_h = refit_and_forecast_exog(hist_y, hist_ex, h, fut_ex)\n",
    "            preds_by_h[h][target_idx] = yhat_h[h - 1]\n",
    "\n",
    "out = pd.DataFrame({\"Date\": test_index, \"Actual\": y_test})\n",
    "out[\"Predicted_1d\"] = preds_by_h[1]\n",
    "out[\"Predicted_2d\"] = preds_by_h[2]\n",
    "out[\"Predicted_3d\"] = preds_by_h[3]\n",
    "out[\"Error_1d\"] = out[\"Actual\"] - out[\"Predicted_1d\"]\n",
    "out[\"Error_2d\"] = out[\"Actual\"] - out[\"Predicted_2d\"]\n",
    "out[\"Error_3d\"] = out[\"Actual\"] - out[\"Predicted_3d\"]\n",
    "\n",
    "out.to_csv(\"Case2_Temporal_MultiHorizon_Predictions_Daily_2022to2024_23.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"\\nSaved: Case2_Temporal_MultiHorizon_Predictions_Daily_2022to2024_23.csv\")\n",
    "print(out.head(10))\n",
    "print(out.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f981412b-965a-418d-973f-e4317cb21543",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cleanml310)",
   "language": "python",
   "name": "cleanml310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
