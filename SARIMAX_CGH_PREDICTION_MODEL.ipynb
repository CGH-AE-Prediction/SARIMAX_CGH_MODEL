{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db46f3e9-5bc5-4bd0-acb1-13f0d1e6e10e",
   "metadata": {},
   "source": [
    "# CGH ER ARRIVAL PREDICTION MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d0a1b0-5623-4fb8-9a1c-6b37c3ed43cb",
   "metadata": {},
   "source": [
    "#### Temporal exogenous SARIMAX model\n",
    "#### Training period 2022-01-01 to 2024-12-31\n",
    "#### Testing period 2025-01-01 to 2025-09-30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68ac7629-6966-493c-96df-482bab61eb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing lib\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, gc, warnings\n",
    "import pickle\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import fastf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5440c655-ec6f-488e-bdbe-52626e6d0255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warning\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.simplefilter(\"ignore\", ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c48d20b8-7c11-4c89-83d7-2a201077fd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "CGH_ER_ARRIVALS_CSV_PATH = \"AnE_Data_fin.csv\"\n",
    "CGH_ER_ARRIVALS_2018_2024_CSV_PATH = \"edarrivals_20182024.csv\"\n",
    "CGH_ER_ARRIVALS_2025_CSV_PATH = \"edarrivals_2025.csv\"\n",
    "CGH_CALENDAR_CSV_PATH = \"calendar_2018_2026.csv\"\n",
    "\n",
    "CGH_TRAIN_START_DATE = \"2022-01-01\"\n",
    "CGH_TRAIN_END_DATE   = \"2024-12-31\"\n",
    "CGH_TEST_START_DATE  = \"2025-01-01\"\n",
    "CGH_TEST_END_DATE    = \"2025-09-30\"\n",
    "\n",
    "CGH_FULL_START_DATE = CGH_TRAIN_START_DATE\n",
    "CGH_FULL_END_DATE   = CGH_TEST_END_DATE\n",
    "\n",
    "CGH_FORECAST_HOURS = [24, 48, 72]\n",
    "CGH_FORECAST_HORIZON_DAYS = [1, 2, 3]\n",
    "CGH_WEEKLY_SEASONAL_PERIOD = 7\n",
    "\n",
    "# Output names\n",
    "CGH_MULTI_HORIZON_CSV = \"CGH_ER_MultiHorizon_Predictions_Daily_Train2022to2024_Test2025_JnToSep.csv\"\n",
    "CGH_PROD_MODEL_PKL    = \"CGH_ER_SARIMAX_TemporalExog_ProdModel_FullFit_2022to2025.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1fada00-f5cf-4f43-9040-14cbe07492db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  PUBLIC HOLIDAY FLAG USING CALENDAR CSV\n",
    "cgh_full_index = pd.date_range(\n",
    "    start=CGH_FULL_START_DATE,\n",
    "    end=CGH_FULL_END_DATE,\n",
    "    freq=\"D\"\n",
    ")\n",
    "cgh_full_index = pd.to_datetime(cgh_full_index).tz_localize(None).normalize()\n",
    "\n",
    "def load_cgh_calendar_df(calendar_csv_path: str) -> pd.DataFrame:\n",
    "    cal = pd.read_csv(calendar_csv_path, low_memory=False)\n",
    "\n",
    "    date_col_candidates = [c for c in cal.columns if str(c).strip().lower() in (\"date\", \"ds\")]\n",
    "    if not date_col_candidates:\n",
    "        raise ValueError(\"calendar_2018_2026.csv must have a Date or ds column.\")\n",
    "\n",
    "    cal = cal.rename(columns={date_col_candidates[0]: \"Date\"})\n",
    "    cal[\"Date\"] = pd.to_datetime(cal[\"Date\"], dayfirst=True, errors=\"coerce\")\n",
    "\n",
    "    cal = cal.dropna(subset=[\"Date\"]).sort_values(\"Date\").set_index(\"Date\")\n",
    "    return cal\n",
    "\n",
    "def build_cgh_public_holiday_flag_from_calendar(\n",
    "    full_index: pd.DatetimeIndex,\n",
    "    calendar_df: pd.DataFrame\n",
    ") -> pd.Series:\n",
    "    full_index = pd.to_datetime(full_index).tz_localize(None).normalize()\n",
    "\n",
    "    preferred_cols = [\n",
    "        c for c in calendar_df.columns\n",
    "        if str(c).strip().lower() in (\n",
    "            \"is_public_holiday\",\n",
    "            \"public_holiday\",\n",
    "            \"is_ph\",\n",
    "            \"ph\",\n",
    "            \"holiday_flag\",\n",
    "            \"is_holiday\"\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    if preferred_cols:\n",
    "        holiday_col = preferred_cols[0]\n",
    "    else:\n",
    "        possible_cols = [\n",
    "            c for c in calendar_df.columns\n",
    "            if (\"holiday\" in str(c).lower()) or (\"public\" in str(c).lower())\n",
    "        ]\n",
    "        if not possible_cols:\n",
    "            return pd.Series(0, index=full_index, dtype=int, name=\"holiday\")\n",
    "        holiday_col = possible_cols[0]\n",
    "\n",
    "    s = calendar_df[holiday_col]\n",
    "\n",
    "    if pd.api.types.is_bool_dtype(s):\n",
    "        s = s.astype(int)\n",
    "    elif pd.api.types.is_numeric_dtype(s):\n",
    "        s = s.fillna(0).astype(int)\n",
    "    else:\n",
    "        s = (\n",
    "            s.astype(str).str.strip().str.lower()\n",
    "            .map({\n",
    "                \"1\": 1, \"true\": 1, \"yes\": 1, \"y\": 1, \"t\": 1,\n",
    "                \"holiday\": 1, \"public holiday\": 1, \"ph\": 1\n",
    "            })\n",
    "            .fillna(0)\n",
    "            .astype(int)\n",
    "        )\n",
    "\n",
    "    out = s.reindex(full_index).fillna(0).astype(int)\n",
    "    out.name = \"holiday\"\n",
    "    return out\n",
    "\n",
    "calendar_df = load_cgh_calendar_df(CGH_CALENDAR_CSV_PATH)\n",
    "cgh_public_holiday_flag = build_cgh_public_holiday_flag_from_calendar(\n",
    "    cgh_full_index, calendar_df\n",
    ")\n",
    "\n",
    "# OTHER PUBLIC HOLIDAYS: POST +1 to +2 ONLY\n",
    "def build_cgh_holiday_post_window(\n",
    "    full_index: pd.DatetimeIndex,\n",
    "    holiday_flag: pd.Series,\n",
    "    post_days: int = 2\n",
    ") -> pd.Series:\n",
    "    hol = holiday_flag.reindex(full_index).fillna(0).astype(int)\n",
    "    post = pd.Series(0, index=full_index, dtype=int)\n",
    "\n",
    "    hol_pos = np.where(hol.values == 1)[0]\n",
    "    for p in hol_pos:\n",
    "        start = p + 1\n",
    "        end   = min(p + post_days, len(post) - 1)\n",
    "        if start <= end:\n",
    "            post.iloc[start:end + 1] = 1\n",
    "\n",
    "    post.name = \"holiday_post_window_2d\"\n",
    "    return post\n",
    "\n",
    "cgh_holiday_post_window_2d = build_cgh_holiday_post_window(\n",
    "    cgh_full_index, cgh_public_holiday_flag, post_days=2\n",
    ")\n",
    "\n",
    "# CNY DETECTION (2 consecutive PH days)\n",
    "def build_cgh_cny_flag_from_holiday_flag(\n",
    "    full_index: pd.DatetimeIndex,\n",
    "    holiday_flag: pd.Series\n",
    ") -> pd.Series:\n",
    "    hol = holiday_flag.reindex(full_index).fillna(0).astype(int)\n",
    "    cny = pd.Series(0, index=full_index, dtype=int)\n",
    "\n",
    "    i = 0\n",
    "    while i < len(hol) - 1:\n",
    "        if hol.iloc[i] == 1 and hol.iloc[i + 1] == 1:\n",
    "            cny.iloc[i:i+2] = 1\n",
    "            i += 2\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "    cny.name = \"cny_flag\"\n",
    "    return cny\n",
    "\n",
    "def build_cgh_cny_post_window(\n",
    "    full_index: pd.DatetimeIndex,\n",
    "    cny_flag: pd.Series,\n",
    "    post_days: int = 4\n",
    ") -> pd.Series:\n",
    "    post = pd.Series(0, index=full_index, dtype=int)\n",
    "    idx = np.where(cny_flag.values == 1)[0]\n",
    "\n",
    "    if idx.size > 0:\n",
    "        breaks = np.where(np.diff(idx) != 1)[0]\n",
    "        block_ends = np.r_[breaks, len(idx) - 1]\n",
    "\n",
    "        for be in block_ends:\n",
    "            end_pos = idx[be]\n",
    "            post.iloc[end_pos + 1 : min(end_pos + post_days + 1, len(post))] = 1\n",
    "\n",
    "    post.name = \"cny_post_window\"\n",
    "    return post\n",
    "\n",
    "cgh_cny_flag = build_cgh_cny_flag_from_holiday_flag(\n",
    "    cgh_full_index, cgh_public_holiday_flag\n",
    ")\n",
    "\n",
    "cgh_cny_post_window = build_cgh_cny_post_window(\n",
    "    cgh_full_index, cgh_cny_flag, post_days=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1717bb67-aa5f-4d0a-b2a2-d1f955a5cb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV LOADING + ROBUST DATETIME PARSING\n",
    "def try_parse_datetime(series, fmt=None, dayfirst=False):\n",
    "    return pd.to_datetime(series, format=fmt, errors=\"coerce\", dayfirst=dayfirst)\n",
    "\n",
    "def parse_cgh_admit_datetime(df):\n",
    "    s = df[\"A&E Admit Date Time\"]\n",
    "    dt = pd.Series(pd.NaT, index=df.index, dtype=\"datetime64[ns]\")\n",
    "\n",
    "    cand = try_parse_datetime(s, \"%m/%d/%Y %I:%M:%S %p\", dayfirst=False)\n",
    "    dt = dt.fillna(cand)\n",
    "\n",
    "    cand = try_parse_datetime(s, \"%m/%d/%Y %I:%M %p\", dayfirst=False)\n",
    "    dt = dt.fillna(cand)\n",
    "\n",
    "    cand = try_parse_datetime(s, \"%d/%m/%Y %H:%M:%S\", dayfirst=True)\n",
    "    dt = dt.fillna(cand)\n",
    "\n",
    "    cand = try_parse_datetime(s, \"%d/%m/%Y %H:%M\", dayfirst=True)\n",
    "    dt = dt.fillna(cand)\n",
    "\n",
    "    cand = pd.to_datetime(s, errors=\"coerce\", dayfirst=True, infer_datetime_format=True)\n",
    "    dt = dt.fillna(cand)\n",
    "\n",
    "    cand = pd.to_datetime(s, errors=\"coerce\", dayfirst=False, infer_datetime_format=True)\n",
    "    dt = dt.fillna(cand)\n",
    "\n",
    "    if \"A&E Admit Date\" in df.columns:\n",
    "        d_only = pd.to_datetime(df[\"A&E Admit Date\"], errors=\"coerce\", dayfirst=True)\n",
    "        dt = dt.where(dt.notna(), d_only)\n",
    "\n",
    "    return dt\n",
    "\n",
    "# Merge into AnE_Data_fin.csv\n",
    "def build_unified_cgh_arrivals_csv(\n",
    "    csv_2018_2024_path,\n",
    "    csv_2025_path,\n",
    "    output_csv_path\n",
    "):\n",
    "    df_2018_2024 = pd.read_csv(csv_2018_2024_path, low_memory=False)\n",
    "    df_2025 = pd.read_csv(csv_2025_path, low_memory=False)\n",
    "\n",
    "    df_all = pd.concat([df_2018_2024, df_2025], ignore_index=True)\n",
    "\n",
    "    if \"A&E Discharge Type Description\" in df_all.columns:\n",
    "        df_all = df_all[df_all[\"A&E Discharge Type Description\"] != \"Cancellation\"].copy()\n",
    "\n",
    "    df_all.to_csv(output_csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "# Build the unified file\n",
    "build_unified_cgh_arrivals_csv(\n",
    "    CGH_ER_ARRIVALS_2018_2024_CSV_PATH,\n",
    "    CGH_ER_ARRIVALS_2025_CSV_PATH,\n",
    "    CGH_ER_ARRIVALS_CSV_PATH\n",
    ")\n",
    "\n",
    "def load_cgh_daily_arrivals_from_csv(csv_path, start_date, end_date):\n",
    "    df = pd.read_csv(csv_path, low_memory=False)\n",
    "\n",
    "    if \"A&E Triage Class (Computed)\" in df.columns:\n",
    "        df = df[df[\"A&E Triage Class (Computed)\"] != \"P4\"].copy()\n",
    "\n",
    "    dt = parse_cgh_admit_datetime(df)\n",
    "    df = df.assign(dt=dt).dropna(subset=[\"dt\"])\n",
    "\n",
    "    df[\"day\"] = pd.to_datetime(df[\"dt\"], errors=\"coerce\").dt.floor(\"D\")\n",
    "    df = df.dropna(subset=[\"day\"])\n",
    "\n",
    "    start_ts = pd.Timestamp(start_date)\n",
    "    end_ts = pd.Timestamp(end_date)\n",
    "    df = df[(df[\"day\"] >= start_ts) & (df[\"day\"] <= end_ts)].copy()\n",
    "\n",
    "    daily_counts = df.groupby(\"day\", sort=True).size()\n",
    "\n",
    "    # Ensure strictly sorted by day\n",
    "    daily_counts = daily_counts.sort_index()\n",
    "\n",
    "    full_index = pd.date_range(start=start_ts, end=end_ts, freq=\"D\")\n",
    "    full_index = pd.to_datetime(full_index).tz_localize(None).normalize()\n",
    "\n",
    "    s = daily_counts.reindex(full_index, fill_value=0).astype(float)\n",
    "    s.index = pd.to_datetime(s.index).tz_localize(None).normalize()\n",
    "    s.index.name = \"Date\"\n",
    "    s.name = \"Arrivals\"\n",
    "\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34492c97-6d1b-4907-9c81-7a1098b92b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD TRAIN/TEST\n",
    "cgh_train_arrivals = load_cgh_daily_arrivals_from_csv(\n",
    "    CGH_ER_ARRIVALS_CSV_PATH,\n",
    "    CGH_TRAIN_START_DATE,\n",
    "    CGH_TRAIN_END_DATE\n",
    ")\n",
    "\n",
    "cgh_test_arrivals = load_cgh_daily_arrivals_from_csv(\n",
    "    CGH_ER_ARRIVALS_CSV_PATH,\n",
    "    CGH_TEST_START_DATE,\n",
    "    CGH_TEST_END_DATE\n",
    ")\n",
    "\n",
    "cgh_arrivals_full = pd.concat([cgh_train_arrivals, cgh_test_arrivals]).sort_index()\n",
    "cgh_arrivals_full.index.name = \"Date\"\n",
    "cgh_arrivals_df = cgh_arrivals_full.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f48f77e8-e1a7-4ed5-b119-3132cabffe43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req         WARNING \tDEFAULT CACHE ENABLED! (112.0 KB) C:\\Users\\kchas\\AppData\\Local\\Temp\\fastf1\n"
     ]
    }
   ],
   "source": [
    "# EVENT FEATURES: F1 + CONCERT \n",
    "def build_cgh_f1_event_df():\n",
    "    years = [2022, 2023, 2024, 2025]\n",
    "    all_races = []\n",
    "\n",
    "    for year in years:\n",
    "        df_f1_year = fastf1.get_event_schedule(year)\n",
    "        df_f1_year = df_f1_year[df_f1_year[\"Country\"] == \"Singapore\"]\n",
    "        df_f1_year = df_f1_year[[\"EventDate\", \"Session1Date\"]]\n",
    "        all_races.append(df_f1_year)\n",
    "\n",
    "    # SAFETY: if nothing returned, return empty event df\n",
    "    if len(all_races) == 0:\n",
    "        return pd.DataFrame(columns=[\"ds\", \"f1_event\"])\n",
    "\n",
    "    df_f1 = pd.concat(all_races, ignore_index=True)\n",
    "\n",
    "    # SAFETY: if Singapore filter produced empty df\n",
    "    if df_f1.empty:\n",
    "        return pd.DataFrame(columns=[\"ds\", \"f1_event\"])\n",
    "\n",
    "    df_f1[\"Session1Date\"] = pd.to_datetime(df_f1[\"Session1Date\"]).dt.tz_localize(None).dt.normalize()\n",
    "    df_f1[\"EventDate\"]    = pd.to_datetime(df_f1[\"EventDate\"]).dt.tz_localize(None).dt.normalize()\n",
    "\n",
    "    def get_f1_dates(row):\n",
    "        return pd.date_range(start=row[\"Session1Date\"], end=row[\"EventDate\"])\n",
    "\n",
    "    f1_dates = df_f1.apply(get_f1_dates, axis=1)\n",
    "    f1_dates = pd.DataFrame(f1_dates.explode(), columns=[\"ds\"])\n",
    "    f1_dates[\"ds\"] = pd.to_datetime(f1_dates[\"ds\"]).dt.tz_localize(None).dt.normalize()\n",
    "    f1_dates[\"f1_event\"] = 1\n",
    "    return f1_dates\n",
    "\n",
    "# F1 series \n",
    "try:\n",
    "    cgh_f1_df = build_cgh_f1_event_df().set_index(\"ds\")\n",
    "    f1_series = cgh_f1_df.reindex(cgh_full_index)[\"f1_event\"].fillna(0).astype(int)\n",
    "except Exception:\n",
    "    f1_series = pd.Series(0, index=cgh_full_index, dtype=int)\n",
    "\n",
    "temp_events = f1_series.replace(0, np.nan)\n",
    "cgh_f1_event_window = (\n",
    "    temp_events\n",
    "    .bfill(limit=4)\n",
    "    .ffill(limit=2)\n",
    "    .fillna(0)\n",
    "    .astype(int)\n",
    ")\n",
    "\n",
    "# National Stadium sold out concerts only\n",
    "def build_cgh_concert_event_df():\n",
    "    concert_dates = [\n",
    "        \"2022-12-17\", \"2022-12-18\",\n",
    "        \"2023-05-13\", \"2023-05-14\",\n",
    "        \"2024-01-23\", \"2024-01-24\", \"2024-01-26\", \"2024-01-27\", \"2024-01-30\", \"2024-01-31\",\n",
    "        \"2024-02-16\",\n",
    "        \"2024-03-02\", \"2024-03-03\", \"2024-03-04\", \"2024-03-07\", \"2024-03-08\", \"2024-03-09\",\n",
    "        \"2024-04-03\", \"2024-04-05\", \"2024-04-06\",\n",
    "        \"2024-10-11\", \"2024-10-12\", \"2024-10-13\",\n",
    "        \"2025-01-11\", \"2025-01-12\",\n",
    "        \"2025-01-25\", \"2025-01-26\",\n",
    "        \"2025-02-14\", \"2025-02-15\",\n",
    "        \"2025-03-01\",\n",
    "        \"2025-05-18\", \"2025-05-19\", \"2025-05-21\", \"2025-05-24\"\n",
    "    ]\n",
    "    ds = pd.to_datetime(concert_dates).tz_localize(None).normalize()\n",
    "    df_con = pd.DataFrame({\"ds\": ds})\n",
    "    df_con[\"concert_event\"] = 1\n",
    "    return df_con\n",
    "\n",
    "cgh_concert_df = build_cgh_concert_event_df().set_index(\"ds\")\n",
    "concert_series = cgh_concert_df.reindex(cgh_full_index)[\"concert_event\"].fillna(0).astype(int)\n",
    "\n",
    "temp_con = concert_series.replace(0, np.nan)\n",
    "cgh_concert_event_window = (\n",
    "    temp_con\n",
    "    .bfill(limit=1)\n",
    "    .ffill(limit=2)\n",
    "    .fillna(0)\n",
    "    .astype(int)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "873d8313-8b0f-419f-b5e0-b0a19c4b88c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXOG MATRIX\n",
    "cgh_temporal_exog_df = pd.DataFrame(index=cgh_full_index)\n",
    "\n",
    "cgh_temporal_exog_df[\"dow\"]   = cgh_temporal_exog_df.index.dayofweek\n",
    "cgh_temporal_exog_df[\"dom\"]   = cgh_temporal_exog_df.index.day\n",
    "cgh_temporal_exog_df[\"qtr\"]   = cgh_temporal_exog_df.index.quarter\n",
    "\n",
    "cgh_temporal_exog_df[\"holiday\"] = cgh_public_holiday_flag.reindex(cgh_full_index).fillna(0).astype(int).values\n",
    "cgh_temporal_exog_df[\"holiday_post_window_2d\"] = cgh_holiday_post_window_2d.reindex(cgh_full_index).fillna(0).astype(int).values\n",
    "cgh_temporal_exog_df[\"cny_post_window\"] = cgh_cny_post_window.reindex(cgh_full_index).fillna(0).astype(int).values\n",
    "\n",
    "# dom_norm\n",
    "cgh_temporal_exog_df[\"dom_norm\"] = (\n",
    "    (cgh_temporal_exog_df[\"dom\"] - cgh_temporal_exog_df[\"dom\"].mean())\n",
    "    / (cgh_temporal_exog_df[\"dom\"].std() + 1e-8)\n",
    ")\n",
    "\n",
    "# Holiday window\n",
    "temp_hol = cgh_temporal_exog_df[\"holiday\"].replace(0, np.nan)\n",
    "cgh_temporal_exog_df[\"holiday_window\"] = (\n",
    "    temp_hol.bfill(limit=2).ffill(limit=2).fillna(0).astype(int)\n",
    ")\n",
    "\n",
    "# Event windows\n",
    "cgh_temporal_exog_df[\"f1_event\"] = (\n",
    "    pd.Series(cgh_f1_event_window, index=cgh_full_index)\n",
    "    .reindex(cgh_full_index)\n",
    "    .fillna(0)\n",
    "    .astype(int)\n",
    "    .values\n",
    ")\n",
    "\n",
    "cgh_temporal_exog_df[\"concert_event\"] = (\n",
    "    pd.Series(cgh_concert_event_window, index=cgh_full_index)\n",
    "    .reindex(cgh_full_index)\n",
    "    .fillna(0)\n",
    "    .astype(int)\n",
    "    .values\n",
    ")\n",
    "\n",
    "# dummies\n",
    "dow_dummies   = pd.get_dummies(cgh_temporal_exog_df[\"dow\"], prefix=\"dow\", drop_first=True)\n",
    "qtr_dummies   = pd.get_dummies(cgh_temporal_exog_df[\"qtr\"], prefix=\"qtr\", drop_first=True)\n",
    "\n",
    "cgh_exog_full = pd.concat(\n",
    "    [\n",
    "        dow_dummies,\n",
    "        qtr_dummies,\n",
    "        cgh_temporal_exog_df[\n",
    "            [\n",
    "                \"dom_norm\",\n",
    "                \"holiday\",\n",
    "                \"holiday_window\",\n",
    "                \"holiday_post_window_2d\",\n",
    "                \"cny_post_window\",\n",
    "                \"f1_event\",\n",
    "                \"concert_event\",\n",
    "            ]\n",
    "        ],\n",
    "    ],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "cgh_exog_full = (\n",
    "    cgh_exog_full.apply(pd.to_numeric, errors=\"coerce\")\n",
    "    .replace([np.inf, -np.inf], np.nan)\n",
    "    .fillna(0.0)\n",
    "    .astype(\"float64\")\n",
    ")\n",
    "\n",
    "# align exog to arrivals df (index is 2022–2025)\n",
    "cgh_exog_full = cgh_exog_full.reindex(cgh_arrivals_df.index).fillna(0.0)\n",
    "\n",
    "# Train/Test slices\n",
    "cgh_train_df = cgh_arrivals_df.loc[CGH_TRAIN_START_DATE:CGH_TRAIN_END_DATE]\n",
    "cgh_test_df  = cgh_arrivals_df.loc[CGH_TEST_START_DATE:CGH_TEST_END_DATE]\n",
    "\n",
    "cgh_y_train = cgh_train_df[\"Arrivals\"].values.astype(float)\n",
    "cgh_y_test  = cgh_test_df[\"Arrivals\"].values.astype(float)\n",
    "\n",
    "cgh_train_exog = cgh_exog_full.loc[cgh_train_df.index]\n",
    "cgh_test_exog  = cgh_exog_full.loc[cgh_test_df.index]\n",
    "\n",
    "cgh_test_index = cgh_test_df.index\n",
    "\n",
    "if np.all(cgh_y_train == 0) or np.all(cgh_y_test == 0):\n",
    "    raise ValueError(\"Train or test arrivals are all zeros. Check inputs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fcf28ea-c3ed-437d-b289-d77a4650585b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation METRICS + SARIMAX REFIT/FORECAST\n",
    "def compute_directional_accuracy_window(y_true_vec, y_pred_vec):\n",
    "    yt = np.asarray(y_true_vec, float)\n",
    "    yp = np.asarray(y_pred_vec, float)\n",
    "    if len(yt) < 2 or len(yp) < 2:\n",
    "        return np.nan\n",
    "    return (np.sign(np.diff(yt)) == np.sign(np.diff(yp))).mean() * 100.0\n",
    "\n",
    "def compute_mape_percent(y_true_vec, y_pred_vec):\n",
    "    yt = np.asarray(y_true_vec, float)\n",
    "    yp = np.asarray(y_pred_vec, float)\n",
    "    mask = (yt != 0) & ~np.isnan(yt) & ~np.isnan(yp)\n",
    "    if mask.sum() == 0:\n",
    "        return np.nan\n",
    "    return np.mean(np.abs((yt[mask] - yp[mask]) / yt[mask])) * 100.0\n",
    "\n",
    "def compute_global_rmse_from_errors(err_vec):\n",
    "    err = np.asarray(err_vec, float)\n",
    "    err = err[~np.isnan(err)]\n",
    "    if err.size == 0:\n",
    "        return np.nan\n",
    "    return float(np.sqrt(np.mean(err ** 2)))\n",
    "\n",
    "def refit_cgh_sarimax_and_forecast(history_y, history_exog, steps, future_exog):\n",
    "    model = SARIMAX(\n",
    "        history_y,\n",
    "        exog=history_exog,\n",
    "        order=(1, 1, 1),\n",
    "        seasonal_order=(1, 1, 1, CGH_WEEKLY_SEASONAL_PERIOD),\n",
    "        enforce_stationarity=False,\n",
    "        enforce_invertibility=False,\n",
    "    )\n",
    "    res = model.fit(disp=False)\n",
    "    yhat = np.asarray(res.get_forecast(steps=steps, exog=future_exog).predicted_mean, dtype=float)\n",
    "    return np.clip(yhat, 0.0, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7372f8d3-918f-4f23-a57e-623b1f34bdf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CGH ER SARIMAX Temporal Exogenous — Walk Forward Evaluation\n",
      "Train: 2022-01-01 to 2024-12-31 | Test: 2025-01-01 to 2025-09-30\n",
      "24h (~1 day) → RMSE 24.13 | MAE 18.53 | MAPE 4.92% | DA 83.09% \n",
      "48h (~2 day) → RMSE 24.23 | MAE 18.72 | MAPE 4.98% | DA 76.84% \n",
      "72h (~3 day) → RMSE 24.40 | MAE 18.81 | MAPE 5.00% | DA 76.94% \n",
      "\n",
      "Runtime: 3565.26 seconds\n"
     ]
    }
   ],
   "source": [
    "# WALK-FORWARD EVALUATION\n",
    "cgh_test_length = len(cgh_y_test)\n",
    "cgh_max_horizon = max(CGH_FORECAST_HORIZON_DAYS)  # should be 3\n",
    "\n",
    "# Storage for table \n",
    "cgh_preds_by_horizon = {\n",
    "    h: np.full(cgh_test_length, np.nan, dtype=float)\n",
    "    for h in CGH_FORECAST_HORIZON_DAYS\n",
    "}\n",
    "\n",
    "# Storage for metrics\n",
    "cgh_walk_forward_results = {\n",
    "    h: {\n",
    "        \"sq_err\": [],    \n",
    "        \"abs_err\": [],    \n",
    "        \"mape\": [],       \n",
    "        \"da\": []          \n",
    "    }\n",
    "    for h in CGH_FORECAST_HORIZON_DAYS\n",
    "}\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "# Main walk-forward (origin i = 0..N-1)\n",
    "for i in range(cgh_test_length):\n",
    "\n",
    "    # build history up to i-1 (same as your logic)\n",
    "    history_y = np.r_[cgh_y_train, cgh_y_test[:i]]\n",
    "    if i > 0:\n",
    "        history_exog = np.vstack([cgh_train_exog.values, cgh_test_exog.values[:i]])\n",
    "    else:\n",
    "        history_exog = cgh_train_exog.values\n",
    "\n",
    "    # we can only forecast up to what's left in test\n",
    "    steps = min(cgh_max_horizon, cgh_test_length - i)\n",
    "    if steps <= 0:\n",
    "        continue\n",
    "\n",
    "    future_exog = cgh_test_exog.values[i:i + steps]\n",
    "\n",
    "    try:\n",
    "        preds = refit_cgh_sarimax_and_forecast(history_y, history_exog, steps, future_exog)\n",
    "    except Exception as e:\n",
    "        if i == 0:\n",
    "            print(\"First refit/forecast error:\", repr(e))\n",
    "            print(\"history_y shape:\", history_y.shape)\n",
    "            print(\"history_exog shape:\", np.asarray(history_exog).shape)\n",
    "            print(\"future_exog shape:\", np.asarray(future_exog).shape)\n",
    "        continue\n",
    "\n",
    "    # Fill the prediction table\n",
    "    for h in CGH_FORECAST_HORIZON_DAYS:\n",
    "        target_idx = i + h - 1\n",
    "        if target_idx < cgh_test_length and h <= steps:\n",
    "            cgh_preds_by_horizon[h][target_idx] = preds[h - 1]\n",
    "\n",
    "    # Evaluation matrix\n",
    "    for h in CGH_FORECAST_HORIZON_DAYS:\n",
    "        if h > steps:\n",
    "            continue\n",
    "\n",
    "        true_h = cgh_y_test[i:i + h]\n",
    "        pred_h = preds[:h]\n",
    "\n",
    "        if np.isnan(true_h).any() or np.isnan(pred_h).any():\n",
    "            continue\n",
    "\n",
    "        err = (true_h - pred_h)\n",
    "\n",
    "        # RMSE and MAE\n",
    "        cgh_walk_forward_results[h][\"sq_err\"].extend(list(err ** 2))\n",
    "        cgh_walk_forward_results[h][\"abs_err\"].extend(list(np.abs(err)))\n",
    "\n",
    "        # MAPE\n",
    "        cgh_walk_forward_results[h][\"mape\"].append(compute_mape_percent(true_h, pred_h))\n",
    "\n",
    "        # DA\n",
    "        if h == 1:\n",
    "            # direction vs previous actual \n",
    "            if i >= 1:\n",
    "                prev_actual = cgh_y_test[i - 1]\n",
    "                dir_true = np.sign(true_h[0] - prev_actual)\n",
    "                dir_pred = np.sign(pred_h[0] - prev_actual)\n",
    "                cgh_walk_forward_results[h][\"da\"].append(100.0 if dir_true == dir_pred else 0.0)\n",
    "        else:\n",
    "            # directional accuracy inside the h-length window\n",
    "            cgh_walk_forward_results[h][\"da\"].append(compute_directional_accuracy_window(true_h, pred_h))\n",
    "\n",
    "    if i % 30 == 0:\n",
    "        gc.collect()\n",
    "\n",
    "elapsed = time.time() - t0        \n",
    "\n",
    "# Print summary\n",
    "print(\"\\nCGH ER SARIMAX Temporal Exogenous — Walk Forward Evaluation\")\n",
    "print(f\"Train: {CGH_TRAIN_START_DATE} to {CGH_TRAIN_END_DATE} | Test: {CGH_TEST_START_DATE} to {CGH_TEST_END_DATE}\")\n",
    "\n",
    "for hrs, h in zip(CGH_FORECAST_HOURS, CGH_FORECAST_HORIZON_DAYS):\n",
    "    sq = np.asarray(cgh_walk_forward_results[h][\"sq_err\"], float)\n",
    "    ae = np.asarray(cgh_walk_forward_results[h][\"abs_err\"], float)\n",
    "    mp = np.asarray(cgh_walk_forward_results[h][\"mape\"], float)\n",
    "    da = np.asarray(cgh_walk_forward_results[h][\"da\"], float)\n",
    "\n",
    "    rmse = np.sqrt(np.mean(sq)) if sq.size else np.nan\n",
    "    mae  = np.mean(ae) if ae.size else np.nan\n",
    "    mape = np.nanmean(mp) if mp.size else np.nan\n",
    "    da_m = np.nanmean(da) if da.size else np.nan\n",
    "\n",
    "    print(\n",
    "        f\"{hrs}h (~{h} day) → RMSE {rmse:.2f} | \"\n",
    "        f\"MAE {mae:.2f} | \"\n",
    "        f\"MAPE {mape:.2f}% | \"\n",
    "        f\"DA {da_m:.2f}% \"\n",
    "    )\n",
    "\n",
    "print(f\"\\nRuntime: {elapsed:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07f51c4c-6641-47bc-9b1d-84a8abb182b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved: CGH_ER_MultiHorizon_Predictions_Daily_Train2022to2024_Test2025_JnToSep.csv\n",
      "        Date  Actual_Arrivals  Predicted_Arrivals_1d  Predicted_Arrivals_2d  \\\n",
      "0 2025-01-01            397.0                 359.39                    NaN   \n",
      "1 2025-01-02            436.0                 417.52                 403.31   \n",
      "2 2025-01-03            409.0                 418.27                 413.91   \n",
      "3 2025-01-04            352.0                 356.33                 362.99   \n",
      "4 2025-01-05            354.0                 362.39                 359.38   \n",
      "5 2025-01-06            461.0                 464.21                 465.54   \n",
      "6 2025-01-07            409.0                 417.07                 422.01   \n",
      "7 2025-01-08            410.0                 406.18                 408.74   \n",
      "8 2025-01-09            357.0                 402.84                 397.92   \n",
      "9 2025-01-10            379.0                 411.60                 420.47   \n",
      "\n",
      "   Predicted_Arrivals_3d  \n",
      "0                    NaN  \n",
      "1                    NaN  \n",
      "2                 400.74  \n",
      "3                 360.20  \n",
      "4                 365.42  \n",
      "5                 461.62  \n",
      "6                 423.03  \n",
      "7                 413.26  \n",
      "8                 399.90  \n",
      "9                 408.43  \n",
      "          Date  Actual_Arrivals  Predicted_Arrivals_1d  Predicted_Arrivals_2d  \\\n",
      "263 2025-09-21            335.0                 335.67                 330.89   \n",
      "264 2025-09-22            462.0                 441.57                 439.70   \n",
      "265 2025-09-23            401.0                 400.05                 396.34   \n",
      "266 2025-09-24            386.0                 389.21                 388.33   \n",
      "267 2025-09-25            388.0                 381.85                 383.15   \n",
      "268 2025-09-26            410.0                 376.23                 375.09   \n",
      "269 2025-09-27            350.0                 341.91                 335.40   \n",
      "270 2025-09-28            329.0                 344.25                 342.74   \n",
      "271 2025-09-29            463.0                 449.30                 452.44   \n",
      "272 2025-09-30            402.0                 405.60                 403.56   \n",
      "\n",
      "     Predicted_Arrivals_3d  \n",
      "263                 331.01  \n",
      "264                 437.29  \n",
      "265                 395.39  \n",
      "266                 385.16  \n",
      "267                 382.30  \n",
      "268                 376.43  \n",
      "269                 334.49  \n",
      "270                 336.91  \n",
      "271                 450.85  \n",
      "272                 406.33  \n"
     ]
    }
   ],
   "source": [
    "# MULTI-HORIZON PREDICTION TABLE\n",
    "cgh_multi_horizon_table = pd.DataFrame(\n",
    "    {\"Date\": cgh_test_index, \"Actual_Arrivals\": cgh_y_test}\n",
    ")\n",
    "\n",
    "cgh_multi_horizon_table[\"Predicted_Arrivals_1d\"] = cgh_preds_by_horizon[1]\n",
    "cgh_multi_horizon_table[\"Predicted_Arrivals_2d\"] = cgh_preds_by_horizon[2]\n",
    "cgh_multi_horizon_table[\"Predicted_Arrivals_3d\"] = cgh_preds_by_horizon[3]\n",
    "\n",
    "cgh_multi_horizon_table[\"Predicted_Arrivals_1d\"] = cgh_multi_horizon_table[\"Predicted_Arrivals_1d\"].round(2)\n",
    "cgh_multi_horizon_table[\"Predicted_Arrivals_2d\"] = cgh_multi_horizon_table[\"Predicted_Arrivals_2d\"].round(2)\n",
    "cgh_multi_horizon_table[\"Predicted_Arrivals_3d\"] = cgh_multi_horizon_table[\"Predicted_Arrivals_3d\"].round(2)\n",
    "\n",
    "cgh_multi_horizon_table.to_csv(CGH_MULTI_HORIZON_CSV, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"\\nSaved: {CGH_MULTI_HORIZON_CSV}\")\n",
    "print(cgh_multi_horizon_table.head(10))\n",
    "print(cgh_multi_horizon_table.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ba4e861-a02d-42d7-a703-6aaa3a0d7ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved CGH ER production model bundle: CGH_ER_SARIMAX_TemporalExog_ProdModel_FullFit_2022to2025.pkl\n",
      "Last observed date saved in bundle: 2025-09-30 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# PRODUCTION MODEL PACKAGING \n",
    "cgh_exog_prod = cgh_exog_full.reindex(cgh_arrivals_full.index).fillna(0.0)\n",
    "\n",
    "cgh_er_prod_model = SARIMAX(\n",
    "    cgh_arrivals_full.values.astype(float),\n",
    "    exog=cgh_exog_prod.values,\n",
    "    order=(1, 1, 1),\n",
    "    seasonal_order=(1, 1, 1, CGH_WEEKLY_SEASONAL_PERIOD),\n",
    "    enforce_stationarity=False,\n",
    "    enforce_invertibility=False\n",
    ")\n",
    "\n",
    "cgh_er_prod_results = cgh_er_prod_model.fit(disp=False)\n",
    "\n",
    "last_observed_date = (\n",
    "    pd.to_datetime(cgh_arrivals_full.index.max())\n",
    "    .tz_localize(None)\n",
    "    .normalize()\n",
    ")\n",
    "\n",
    "cgh_er_model_bundle = {\n",
    "    # model\n",
    "    \"sarimax_results\": cgh_er_prod_results,\n",
    "\n",
    "    # exog metadata\n",
    "    \"exogenous_feature_columns\": list(cgh_exog_full.columns),\n",
    "\n",
    "    # normalization stats\n",
    "    \"dom_mean\": float(cgh_temporal_exog_df[\"dom\"].mean()),\n",
    "    \"dom_std\": float(cgh_temporal_exog_df[\"dom\"].std()),\n",
    "\n",
    "    # holiday logic \n",
    "    \"holiday_pre_days\": 0,\n",
    "    \"holiday_post_days\": 2,\n",
    "    \"cny_post_days\": 4,\n",
    "\n",
    "    # training info\n",
    "    \"train_start\": CGH_TRAIN_START_DATE,\n",
    "    \"train_end\": CGH_TRAIN_END_DATE,\n",
    "    \"full_fit_start\": CGH_FULL_START_DATE,\n",
    "    \"full_fit_end\": CGH_FULL_END_DATE,\n",
    "\n",
    "    # anchor\n",
    "    \"last_observed_date\": str(last_observed_date),\n",
    "}\n",
    "\n",
    "with open(CGH_PROD_MODEL_PKL, \"wb\") as f:\n",
    "    pickle.dump(cgh_er_model_bundle, f)\n",
    "\n",
    "print(f\"Saved CGH ER production model bundle: {CGH_PROD_MODEL_PKL}\")\n",
    "print(f\"Last observed date saved in bundle: {last_observed_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f5b96fa-4897-428c-adff-5dfb85fcceff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------------+------------------------------------------------------------------+---------------+\n",
      "|   rank | column_name            | description                                                      |   coefficient |\n",
      "+========+========================+==================================================================+===============+\n",
      "|      1 | holiday                | Public holiday flag (1=holiday).                                 |    -39.0334   |\n",
      "+--------+------------------------+------------------------------------------------------------------+---------------+\n",
      "|      2 | holiday_post_window_2d | 1 for +1 to +2 days after a holiday (holiday day=0).             |     20.657    |\n",
      "+--------+------------------------+------------------------------------------------------------------+---------------+\n",
      "|      3 | qtr_2                  | Quarter  (Q2 vs Q1 baseline).                                    |     19.4921   |\n",
      "+--------+------------------------+------------------------------------------------------------------+---------------+\n",
      "|      4 | qtr_3                  | Quarter  (Q3 vs Q1 baseline).                                    |     16.0264   |\n",
      "+--------+------------------------+------------------------------------------------------------------+---------------+\n",
      "|      5 | f1_event               | Singapore F1 event window.                                       |     10.5869   |\n",
      "+--------+------------------------+------------------------------------------------------------------+---------------+\n",
      "|      6 | qtr_4                  | Quarter  (Q4 vs Q1 baseline).                                    |     -8.66377  |\n",
      "+--------+------------------------+------------------------------------------------------------------+---------------+\n",
      "|      7 | concert_event          | Sold-out concert event window.                                   |      8.0176   |\n",
      "+--------+------------------------+------------------------------------------------------------------+---------------+\n",
      "|      8 | holiday_window         | Holiday +/-2-day window.                                         |     -3.62245  |\n",
      "+--------+------------------------+------------------------------------------------------------------+---------------+\n",
      "|      9 | cny_post_window        | 1 for +1 to +4 days after detected 2-day CNY block (CNY days=0). |      2.37874  |\n",
      "+--------+------------------------+------------------------------------------------------------------+---------------+\n",
      "|     10 | dom_norm               | Exogenous feature.                                               |     -0.470175 |\n",
      "+--------+------------------------+------------------------------------------------------------------+---------------+\n",
      "|     11 | dow_4                  | Day-of-week.                                                     |     -0.003399 |\n",
      "+--------+------------------------+------------------------------------------------------------------+---------------+\n",
      "|     12 | dow_5                  | Day-of-week.                                                     |      0.002053 |\n",
      "+--------+------------------------+------------------------------------------------------------------+---------------+\n",
      "|     13 | dow_3                  | Day-of-week.                                                     |     -0.00198  |\n",
      "+--------+------------------------+------------------------------------------------------------------+---------------+\n",
      "|     14 | dow_2                  | Day-of-week.                                                     |     -0.001118 |\n",
      "+--------+------------------------+------------------------------------------------------------------+---------------+\n",
      "|     15 | dow_6                  | Day-of-week.                                                     |     -0.000605 |\n",
      "+--------+------------------------+------------------------------------------------------------------+---------------+\n",
      "|     16 | dow_1                  | Day-of-week.                                                     |     -2.8e-05  |\n",
      "+--------+------------------------+------------------------------------------------------------------+---------------+\n"
     ]
    }
   ],
   "source": [
    "#Feature extraction\n",
    "def get_param_map(sarimax_results):\n",
    "    names = list(getattr(sarimax_results, \"param_names\", []))\n",
    "    vals = np.asarray(getattr(sarimax_results, \"params\", []), dtype=float)\n",
    "\n",
    "    if len(names) != len(vals):\n",
    "        try:\n",
    "            s = pd.Series(sarimax_results.params, index=sarimax_results.param_names)\n",
    "            return s.to_dict()\n",
    "        except Exception:\n",
    "            raise ValueError(f\"Cannot map param_names to params (names={len(names)} vs vals={len(vals)}).\")\n",
    "\n",
    "    return dict(zip(names, vals))\n",
    "\n",
    "def describe_feature(col_name: str) -> str:\n",
    "    FEATURE_DESCRIPTIONS = {\n",
    "        \"qtr_2\": \"Quarter  (Q2 vs Q1 baseline).\",\n",
    "        \"qtr_3\": \"Quarter  (Q3 vs Q1 baseline).\",\n",
    "        \"qtr_4\": \"Quarter  (Q4 vs Q1 baseline).\",\n",
    "        \"holiday\": \"Public holiday flag (1=holiday).\",\n",
    "        \"holiday_window\": \"Holiday +/-2-day window.\",\n",
    "        \"holiday_post_window_2d\": \"1 for +1 to +2 days after a holiday (holiday day=0).\",\n",
    "        \"cny_post_window\": \"1 for +1 to +4 days after detected 2-day CNY block (CNY days=0).\",\n",
    "        \"f1_event\": \"Singapore F1 event window.\",\n",
    "        \"concert_event\": \"Sold-out concert event window.\",\n",
    "    }\n",
    "    if col_name.startswith(\"dow_\"):\n",
    "        return \"Day-of-week.\"\n",
    "    return FEATURE_DESCRIPTIONS.get(col_name, \"Exogenous feature.\")\n",
    "\n",
    "def build_ranked_feature_table(model_bundle):\n",
    "    res = model_bundle[\"sarimax_results\"]\n",
    "    exog_cols = list(model_bundle[\"exogenous_feature_columns\"])\n",
    "\n",
    "    param_names = list(getattr(res, \"param_names\", []))\n",
    "    params = np.asarray(getattr(res, \"params\", []), dtype=float)\n",
    "\n",
    "    # If names already match\n",
    "    param_map = get_param_map(res)\n",
    "    direct_hits = sum([1 for c in exog_cols if c in param_map])\n",
    "\n",
    "    # If not, it’s probably x1..xK naming -> map by position\n",
    "    if direct_hits == 0:\n",
    "        # Collect any \"x1\", \"x2\", ... params in order\n",
    "        x_like = []\n",
    "        for i, n in enumerate(param_names):\n",
    "            if re.match(r\"^x\\d+$\", str(n).strip(), flags=re.IGNORECASE):\n",
    "                x_like.append((i, n))\n",
    "\n",
    "        # If statsmodels used generic x-params, it should equal number of exog columns\n",
    "        if len(x_like) >= len(exog_cols):\n",
    "            # take first K x-params and map to your exog column order\n",
    "            x_idx = [i for i, _ in x_like[:len(exog_cols)]]\n",
    "            exog_param_vals = params[x_idx]\n",
    "\n",
    "            rows = []\n",
    "            for col, coef in zip(exog_cols, exog_param_vals):\n",
    "                rows.append({\n",
    "                    \"column_name\": col,\n",
    "                    \"description\": describe_feature(col),\n",
    "                    \"coefficient\": float(coef),\n",
    "                    \"abs_coefficient\": abs(float(coef))\n",
    "                })\n",
    "\n",
    "            df = pd.DataFrame(rows)\n",
    "\n",
    "        else:\n",
    "            # fallback: try to find params that start with \"exog\" or contain your col name\n",
    "            rows = []\n",
    "            for col in exog_cols:\n",
    "                coef = np.nan\n",
    "                # try exact\n",
    "                if col in param_map:\n",
    "                    coef = float(param_map[col])\n",
    "                else:\n",
    "                    # try partial match\n",
    "                    for n in param_names:\n",
    "                        if str(col) in str(n):\n",
    "                            coef = float(param_map.get(n, np.nan))\n",
    "                            break\n",
    "                rows.append({\n",
    "                    \"column_name\": col,\n",
    "                    \"description\": describe_feature(col),\n",
    "                    \"coefficient\": coef,\n",
    "                    \"abs_coefficient\": abs(coef) if not np.isnan(coef) else np.nan\n",
    "                })\n",
    "            df = pd.DataFrame(rows)\n",
    "\n",
    "    else:\n",
    "        # normal case (names match)\n",
    "        rows = []\n",
    "        for col in exog_cols:\n",
    "            coef = float(param_map.get(col, np.nan))\n",
    "            rows.append({\n",
    "                \"column_name\": col,\n",
    "                \"description\": describe_feature(col),\n",
    "                \"coefficient\": coef,\n",
    "                \"abs_coefficient\": abs(coef) if not np.isnan(coef) else np.nan\n",
    "            })\n",
    "        df = pd.DataFrame(rows)\n",
    "\n",
    "    # rank + sort by importance\n",
    "    df = df.sort_values(\"abs_coefficient\", ascending=False, na_position=\"last\").reset_index(drop=True)\n",
    "    df.insert(0, \"rank\", np.arange(1, len(df) + 1))\n",
    "    df[\"coefficient\"] = df[\"coefficient\"].round(6)\n",
    "    df = df.drop(columns=[\"abs_coefficient\"])\n",
    "\n",
    "    return df\n",
    "\n",
    "from tabulate import tabulate\n",
    "import pandas as pd\n",
    "\n",
    "def print_boxed_table(df: pd.DataFrame):\n",
    "    df_fmt = df.copy()\n",
    "\n",
    "    # format coefficient nicely\n",
    "    df_fmt[\"coefficient\"] = df_fmt[\"coefficient\"].map(\n",
    "        lambda x: f\"{x:,.6f}\" if pd.notna(x) else \"NA\"\n",
    "    )\n",
    "\n",
    "    print(tabulate(df_fmt, headers=\"keys\", tablefmt=\"grid\", showindex=False))\n",
    "\n",
    "# ---- Usage ----\n",
    "coef_df = build_ranked_feature_table(cgh_er_model_bundle)\n",
    "print_boxed_table(coef_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40be0d1-45ac-446b-bc4e-b16d370a495a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cleanml310)",
   "language": "python",
   "name": "cleanml310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
