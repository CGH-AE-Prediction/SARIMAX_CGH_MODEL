{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f90d035-3c6b-4c1f-9785-057e796c1f72",
   "metadata": {},
   "source": [
    "## CGH ER ARRIVAL PREDICTION - INFERENCE AND APPEND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "802e95ed-05de-42f1-8841-e0fe2b7e4c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT LIB\n",
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import fastf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb751522-07e8-4769-9f0d-65bd04bdaf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG\n",
    "MODEL_PKL_PATH = \"CGH_ER_SARIMAX_TemporalExog_ProdModel_FullFit_2022to2025.pkl\"\n",
    "MOM_URL = \"https://www.mom.gov.sg/employment-practices/public-holidays\"\n",
    "\n",
    "# Concert list (Please update accordingly)\n",
    "CONCERT_DATES = [\n",
    "        \"2025-10-01\", \"2025-11-29\", \"2025-12-31\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97e27a05-6039-45b8-b747-11474f3caf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD MODEL BUNDLE\n",
    "def load_cgh_er_model(path=MODEL_PKL_PATH):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c62424eb-4274-496e-96eb-fcc919d53acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOM HOLIDAY SCRAPER \n",
    "def clean_date_text(s: str) -> str:\n",
    "    s = str(s)\n",
    "    s = re.sub(r\"\\(.*?\\)\", \"\", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def fetch_tables():\n",
    "    return pd.read_html(MOM_URL)\n",
    "\n",
    "def extract_year(year: int, tables):\n",
    "    out = []\n",
    "    date_pattern = re.compile(r\"\\d{1,2}\\s+[A-Za-z]+\\s+20\\d{2}\")\n",
    "\n",
    "    for df in tables:\n",
    "        df.columns = [str(c).strip().lower() for c in df.columns]\n",
    "        if \"date\" not in df.columns:\n",
    "            continue\n",
    "\n",
    "        rows = df[df[\"date\"].astype(str).str.contains(str(year))]\n",
    "        if rows.empty:\n",
    "            continue\n",
    "\n",
    "        rows = rows.copy()\n",
    "        rows[\"date_clean\"] = rows[\"date\"].astype(str).map(clean_date_text)\n",
    "\n",
    "        for _, r in rows.iterrows():\n",
    "            text = r[\"date_clean\"]\n",
    "            matches = date_pattern.findall(text)\n",
    "            parts = matches if matches else [text]\n",
    "\n",
    "            for part in parts:\n",
    "                dt = pd.to_datetime(part, dayfirst=True, errors=\"coerce\")\n",
    "                if pd.isna(dt) or dt.year != year:\n",
    "                    continue\n",
    "                out.append(dt.normalize())\n",
    "\n",
    "    out = sorted(set(out))\n",
    "    return out\n",
    "\n",
    "def build_holiday_flag(full_index: pd.DatetimeIndex) -> pd.Series:\n",
    "    full_index = pd.to_datetime(full_index).tz_localize(None).normalize()\n",
    "    years = sorted(set(full_index.year.tolist()))\n",
    "    y0, y1 = years[0], years[-1]\n",
    "\n",
    "    try:\n",
    "        tables = fetch_tables()\n",
    "        hol_dates = []\n",
    "        for y in range(y0, y1 + 1):\n",
    "            hol_dates.extend(extract_year(y, tables))\n",
    "        hol_set = set(hol_dates)\n",
    "        return pd.Series([1 if d in hol_set else 0 for d in full_index], index=full_index, dtype=int)\n",
    "    except Exception:\n",
    "        return pd.Series(0, index=full_index, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfb8c7f0-5587-4f7c-8ae1-046cef0ab711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONCERT EVENT WINDOW \n",
    "def build_concert_event_window(full_index: pd.DatetimeIndex) -> pd.Series:\n",
    "    full_index = pd.to_datetime(full_index).tz_localize(None).normalize()\n",
    "    ds = pd.to_datetime(CONCERT_DATES, errors=\"coerce\")\n",
    "    ds = pd.to_datetime(ds).tz_localize(None).normalize()\n",
    "    ds = ds[~pd.isna(ds)]\n",
    "\n",
    "    base = pd.Series(0, index=full_index, dtype=int)\n",
    "    base.loc[base.index.isin(set(ds))] = 1\n",
    "\n",
    "    temp = base.replace(0, np.nan)\n",
    "    return (\n",
    "        temp.bfill(limit=1)\n",
    "            .ffill(limit=2)\n",
    "            .fillna(0)\n",
    "            .astype(int)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2ba62ef-3ab2-49ce-90be-6529a909e876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 EVENT WINDOW \n",
    "def build_f1_event_window(full_index: pd.DatetimeIndex) -> pd.Series:\n",
    "    full_index = pd.to_datetime(full_index).tz_localize(None).normalize()\n",
    "    years = sorted(set(full_index.year.tolist()))\n",
    "\n",
    "    all_races = []\n",
    "    for year in years:\n",
    "        df_f1_year = fastf1.get_event_schedule(year)\n",
    "        df_f1_year = df_f1_year[df_f1_year[\"Country\"] == \"Singapore\"]\n",
    "        df_f1_year = df_f1_year[[\"EventDate\", \"Session1Date\"]]\n",
    "        all_races.append(df_f1_year)\n",
    "\n",
    "    if len(all_races) == 0:\n",
    "        return pd.Series(0, index=full_index, dtype=int)\n",
    "\n",
    "    df_f1 = pd.concat(all_races, ignore_index=True)\n",
    "    if df_f1.empty:\n",
    "        return pd.Series(0, index=full_index, dtype=int)\n",
    "\n",
    "    df_f1[\"Session1Date\"] = pd.to_datetime(df_f1[\"Session1Date\"]).dt.tz_localize(None).dt.normalize()\n",
    "    df_f1[\"EventDate\"] = pd.to_datetime(df_f1[\"EventDate\"]).dt.tz_localize(None).dt.normalize()\n",
    "\n",
    "    def get_f1_dates(row):\n",
    "        return pd.date_range(start=row[\"Session1Date\"], end=row[\"EventDate\"], freq=\"D\")\n",
    "\n",
    "    f1_dates = df_f1.apply(get_f1_dates, axis=1)\n",
    "    f1_dates = pd.to_datetime(pd.Series(f1_dates.explode().values)).dt.normalize()\n",
    "    f1_dates = set(f1_dates.dropna().tolist())\n",
    "\n",
    "    base = pd.Series(0, index=full_index, dtype=int)\n",
    "    base.loc[base.index.isin(f1_dates)] = 1\n",
    "\n",
    "    temp = base.replace(0, np.nan)\n",
    "    window = (\n",
    "        temp.bfill(limit=4)\n",
    "            .ffill(limit=2)\n",
    "            .fillna(0)\n",
    "            .astype(int)\n",
    "    )\n",
    "    return window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1592304f-48cb-4799-ad39-705a6401d1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get last observed date from model\n",
    "def get_model_last_observed_date(model_bundle) -> pd.Timestamp:\n",
    "    lod = model_bundle.get(\"last_observed_date\", None)\n",
    "    if lod is not None and str(lod).strip() != \"\" and str(lod).lower() != \"none\":\n",
    "        return pd.to_datetime(lod).tz_localize(None).normalize()\n",
    "\n",
    "    ffe = model_bundle.get(\"full_fit_end\", None)\n",
    "    if ffe is not None and str(ffe).strip() != \"\" and str(ffe).lower() != \"none\":\n",
    "        return pd.to_datetime(ffe).tz_localize(None).normalize()\n",
    "\n",
    "    raise ValueError(\n",
    "        \"Cannot detect last observed date from the saved model bundle. \"\n",
    "        \"Expected 'last_observed_date' or 'full_fit_end'.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2547abed-f109-4070-a7c6-6e9fc4d1d193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect datetime column + compute daily arrivals\n",
    "_DT_REGEX = re.compile(r\"\\b\\d{1,2}/\\d{1,2}/\\d{4}\\b\")  # e.g., 30/9/2025\n",
    "\n",
    "def _read_raw_visits(path: str) -> pd.DataFrame:\n",
    "    try:\n",
    "        df = pd.read_csv(path, sep=None, engine=\"python\", dtype=str, encoding_errors=\"ignore\")\n",
    "        if df.shape[1] >= 2:\n",
    "            return df\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Fallback: assume tab-separated, no header\n",
    "    df = pd.read_csv(path, sep=\"\\t\", engine=\"python\", header=None, dtype=str, encoding_errors=\"ignore\")\n",
    "    return df\n",
    "\n",
    "def _pick_best_datetime_column(df: pd.DataFrame) -> str:\n",
    "    best_col = None\n",
    "    best_rate = -1.0\n",
    "\n",
    "    # Work on a sample for speed if huge\n",
    "    sample = df.copy()\n",
    "    if len(sample) > 50000:\n",
    "        sample = sample.sample(50000, random_state=42)\n",
    "\n",
    "    for col in sample.columns:\n",
    "        s = sample[col].astype(str).str.strip()\n",
    "\n",
    "        # quick filter: must contain a date-like token\n",
    "        has_date = s.str.contains(_DT_REGEX, na=False)\n",
    "        if has_date.mean() < 0.05:  # too few date-like values\n",
    "            continue\n",
    "\n",
    "        parsed = pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n",
    "        rate = parsed.notna().mean()\n",
    "\n",
    "        if rate > best_rate:\n",
    "            best_rate = rate\n",
    "            best_col = col\n",
    "\n",
    "    if best_col is None:\n",
    "        raise ValueError(\n",
    "            \"Could not detect a datetime column. \"\n",
    "            \"If your file has no headers, consider adding one or tell me which column is the visit time.\"\n",
    "        )\n",
    "    return best_col\n",
    "\n",
    "def count_arrivals_for_date(raw_visits_path: str, observed_date: str) -> int:\n",
    "    df = _read_raw_visits(raw_visits_path)\n",
    "\n",
    "    dt_col = _pick_best_datetime_column(df)\n",
    "    dt = pd.to_datetime(df[dt_col].astype(str).str.strip(), errors=\"coerce\", dayfirst=True)\n",
    "\n",
    "    obs_date = pd.to_datetime(observed_date).date()\n",
    "    arrivals = int((dt.dt.date == obs_date).sum())\n",
    "\n",
    "    if arrivals == 0:\n",
    "        # Useful debug info if you're accidentally using the wrong date column\n",
    "        non_null = int(dt.notna().sum())\n",
    "        raise ValueError(\n",
    "            f\"Arrivals count is 0 for observed_date={observed_date}. \"\n",
    "            f\"Detected datetime column='{dt_col}'. Parsed non-null datetimes={non_null}/{len(df)}. \"\n",
    "            f\"Double-check the observed_date or which datetime field represents arrival/registration time.\"\n",
    "        )\n",
    "\n",
    "    return arrivals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "959bacc3-0525-466c-b3b0-5a218104830d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD EXOG FOR FUTURE DATES\n",
    "def build_future_exog(model_bundle, future_index: pd.DatetimeIndex) -> pd.DataFrame:\n",
    "    future_index = pd.to_datetime(future_index).tz_localize(None).normalize()\n",
    "\n",
    "    dom_mean = float(model_bundle[\"dom_mean\"])\n",
    "    dom_std = float(model_bundle[\"dom_std\"])\n",
    "    exog_cols = list(model_bundle[\"exogenous_feature_columns\"])\n",
    "\n",
    "    df = pd.DataFrame(index=future_index)\n",
    "\n",
    "    # temporal features\n",
    "    df[\"dow\"] = df.index.dayofweek\n",
    "    df[\"dom\"] = df.index.day\n",
    "    df[\"qtr\"] = df.index.quarter\n",
    "\n",
    "    # holiday flag (MOM scrape)\n",
    "    holiday = build_holiday_flag(future_index)\n",
    "    df[\"holiday\"] = holiday.values\n",
    "\n",
    "    # dom_norm using SAVED mean/std\n",
    "    df[\"dom_norm\"] = (df[\"dom\"] - dom_mean) / (dom_std + 1e-8)\n",
    "\n",
    "    # holiday_window (+/-2)\n",
    "    temp_hol = pd.Series(df[\"holiday\"].values, index=future_index).replace(0, np.nan)\n",
    "    df[\"holiday_window\"] = temp_hol.bfill(limit=2).ffill(limit=2).fillna(0).astype(int).values\n",
    "\n",
    "    # holiday_post_window_2d (+1 to +2 days after each holiday)\n",
    "    hol = pd.Series(df[\"holiday\"].values, index=future_index).fillna(0).astype(int)\n",
    "    post2 = pd.Series(0, index=future_index, dtype=int)\n",
    "    hol_pos = np.where(hol.values == 1)[0]\n",
    "    for p in hol_pos:\n",
    "        start = p + 1\n",
    "        end = min(p + 2, len(post2) - 1)\n",
    "        if start <= end:\n",
    "            post2.iloc[start:end + 1] = 1\n",
    "    df[\"holiday_post_window_2d\"] = post2.values\n",
    "\n",
    "    # cny_post_window: detect 2 consecutive holiday days as CNY block, then +1 to +4 days after\n",
    "    cny_flag = pd.Series(0, index=future_index, dtype=int)\n",
    "    i = 0\n",
    "    while i < len(hol) - 1:\n",
    "        if hol.iloc[i] == 1 and hol.iloc[i + 1] == 1:\n",
    "            cny_flag.iloc[i:i+2] = 1\n",
    "            i += 2\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "    cny_post = pd.Series(0, index=future_index, dtype=int)\n",
    "    idx = np.where(cny_flag.values == 1)[0]\n",
    "    if idx.size > 0:\n",
    "        breaks = np.where(np.diff(idx) != 1)[0]\n",
    "        block_ends = np.r_[breaks, len(idx) - 1]\n",
    "        for be in block_ends:\n",
    "            end_pos = idx[be]\n",
    "            cny_post.iloc[end_pos + 1 : min(end_pos + 4 + 1, len(cny_post))] = 1\n",
    "    df[\"cny_post_window\"] = cny_post.values\n",
    "\n",
    "    # event windows\n",
    "    df[\"f1_event\"] = build_f1_event_window(future_index).values\n",
    "    df[\"concert_event\"] = build_concert_event_window(future_index).values\n",
    "\n",
    "    # dummies \n",
    "    dow_dummies = pd.get_dummies(df[\"dow\"], prefix=\"dow\", drop_first=True)\n",
    "    qtr_dummies = pd.get_dummies(df[\"qtr\"], prefix=\"qtr\", drop_first=True)\n",
    "\n",
    "    exog = pd.concat(\n",
    "        [\n",
    "            dow_dummies,\n",
    "            qtr_dummies,\n",
    "            df[\n",
    "                [\n",
    "                    \"dom_norm\",\n",
    "                    \"holiday\",\n",
    "                    \"holiday_window\",\n",
    "                    \"holiday_post_window_2d\",\n",
    "                    \"cny_post_window\",\n",
    "                    \"f1_event\",\n",
    "                    \"concert_event\",\n",
    "                ]\n",
    "            ],\n",
    "        ],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    exog = (\n",
    "        exog.apply(pd.to_numeric, errors=\"coerce\")\n",
    "            .replace([np.inf, -np.inf], np.nan)\n",
    "            .fillna(0.0)\n",
    "            .astype(\"float64\")\n",
    "    )\n",
    "\n",
    "    # Force columns to match training bundle\n",
    "    for c in exog_cols:\n",
    "        if c not in exog.columns:\n",
    "            exog[c] = 0.0\n",
    "    exog = exog[exog_cols]\n",
    "\n",
    "    return exog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f41b556d-5bb2-4b88-a588-e9c12f11f172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FORECAST\n",
    "def forecast_cgh_er_arrivals_next_3_days(\n",
    "    model_bundle,\n",
    "    observed_date=None,\n",
    "    new_observed_arrivals=None,\n",
    "    new_observed_exog=None,\n",
    "):\n",
    "    sarimax_res = model_bundle[\"sarimax_results\"]\n",
    "    has_append = (new_observed_arrivals is not None) and (len(new_observed_arrivals) > 0)\n",
    "\n",
    "    # Determine anchor date\n",
    "    if has_append:\n",
    "        if observed_date is None:\n",
    "            raise ValueError(\"If you append new data, you must provide observed_date (e.g. '2025-09-01').\")\n",
    "        last_observed_date = pd.to_datetime(observed_date).tz_localize(None).normalize()\n",
    "\n",
    "        # Append (no refit)\n",
    "        arrivals_array = np.asarray(new_observed_arrivals, float)\n",
    "        exog_array = np.asarray(new_observed_exog, float)\n",
    "\n",
    "        # Safety reshape (prevents silent shape bugs)\n",
    "        if arrivals_array.ndim != 1:\n",
    "            arrivals_array = arrivals_array.reshape(-1)\n",
    "        if exog_array.ndim == 1:\n",
    "            exog_array = exog_array.reshape(1, -1)\n",
    "\n",
    "        sarimax_res = sarimax_res.append(endog=arrivals_array, exog=exog_array, refit=False)\n",
    "    else:\n",
    "        # No append -> use model's last date\n",
    "        last_observed_date = get_model_last_observed_date(model_bundle)\n",
    "\n",
    "    # Build next 3 target dates\n",
    "    future_index = pd.date_range(start=last_observed_date + pd.Timedelta(days=1), periods=3, freq=\"D\")\n",
    "\n",
    "    future_exog = build_future_exog(model_bundle, future_index).values\n",
    "    fc = sarimax_res.get_forecast(steps=3, exog=future_exog)\n",
    "\n",
    "    yhat = np.asarray(fc.predicted_mean, dtype=float)\n",
    "    yhat = np.clip(yhat, 0.0, None)\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            \"Last_Observed_Date_Used\": [last_observed_date] * 3,\n",
    "            \"Target_Date\": future_index,\n",
    "            \"Horizon_Days\": [1, 2, 3],\n",
    "            \"Predicted_Arrivals\": yhat,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee71761f-e9f5-4c4c-a48a-116283c59ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE UPDATED BUNDLE (ONLY IF YOU APPEND)\n",
    "def save_updated_model_bundle(model_bundle, save_path: str, updated_results=None, last_observed_date=None):\n",
    "    new_bundle = dict(model_bundle)\n",
    "\n",
    "    if updated_results is not None:\n",
    "        new_bundle[\"sarimax_results\"] = updated_results\n",
    "\n",
    "    if last_observed_date is not None:\n",
    "        new_bundle[\"last_observed_date\"] = str(pd.to_datetime(last_observed_date).tz_localize(None).normalize())\n",
    "\n",
    "    with open(save_path, \"wb\") as f:\n",
    "        pickle.dump(new_bundle, f)\n",
    "\n",
    "    return save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2883da9d-07c4-4393-b9b2-ef7435135f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req         WARNING \tDEFAULT CACHE ENABLED! (112.0 KB) C:\\Users\\kchas\\AppData\\Local\\Temp\\fastf1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last_Observed_Date_Used Target_Date  Horizon_Days  Predicted_Arrivals\n",
      "             2025-09-30  2025-10-01             1          397.511278\n",
      "             2025-09-30  2025-10-02             2          391.717559\n",
      "             2025-09-30  2025-10-03             3          386.677290\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE USAGE\n",
    "# OPTION 1: NO APPEND\n",
    "# This will forecast the NEXT 3 DAYS after the last date already inside the model.\n",
    "if __name__ == \"__main__\":\n",
    "    bundle = load_cgh_er_model(MODEL_PKL_PATH)\n",
    "    pred_df = forecast_cgh_er_arrivals_next_3_days(\n",
    "        bundle,\n",
    "        observed_date=None,\n",
    "        new_observed_arrivals=None,\n",
    "        new_observed_exog=None\n",
    "    )\n",
    "    print(pred_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "807c520d-b487-4332-ade3-a59d6d5797df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last_Observed_Date_Used Target_Date  Horizon_Days  Predicted_Arrivals\n",
      "             2025-10-01  2025-10-02             1          386.928576\n",
      "             2025-10-01  2025-10-03             2          381.176968\n",
      "             2025-10-01  2025-10-04             3          339.650892\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE USAGE\n",
    "# OPTION 2A: APPEND 1 DAY THEN FORECAST (manual entry)\n",
    "if __name__ == \"__main__\":\n",
    "    bundle = load_cgh_er_model(MODEL_PKL_PATH)\n",
    "\n",
    "    OBSERVED_DATE = \"2025-10-01\"  # sample date\n",
    "\n",
    "    # Build the correct exog row for the observed day\n",
    "    observed_idx = pd.DatetimeIndex([pd.to_datetime(OBSERVED_DATE)]).tz_localize(None).normalize()\n",
    "    observed_exog_row = build_future_exog(bundle, observed_idx).iloc[0].values.astype(float)\n",
    "\n",
    "    pred_df = forecast_cgh_er_arrivals_next_3_days(\n",
    "        bundle,\n",
    "        observed_date=OBSERVED_DATE,\n",
    "        new_observed_arrivals=[405.0],              # replace with actual arrivals\n",
    "        new_observed_exog=[observed_exog_row],\n",
    "    )\n",
    "\n",
    "    print(pred_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c0515b5-9296-4bd6-af41-066750fefd58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed arrivals for 2025-10-01: 409\n",
      "Last_Observed_Date_Used Target_Date  Horizon_Days  Predicted_Arrivals\n",
      "             2025-10-01  2025-10-02             1          387.642607\n",
      "             2025-10-01  2025-10-03             2          381.734022\n",
      "             2025-10-01  2025-10-04             3          340.200448\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE USAGE\n",
    "# OPTION 2B: APPEND 1 DAY THEN FORECAST\n",
    "if __name__ == \"__main__\":\n",
    "    bundle = load_cgh_er_model(MODEL_PKL_PATH)\n",
    "\n",
    "    OBSERVED_DATE = \"2025-10-01\" # sample date\n",
    "\n",
    "    # Path to your raw visit-level export\n",
    "    RAW_VISITS_PATH = \"cgh_raw_visits_2025_10_01.csv\"  # change to your file\n",
    "\n",
    "    # Derive the daily arrivals count from raw rows\n",
    "    arrivals_count = count_arrivals_for_date(RAW_VISITS_PATH, OBSERVED_DATE)\n",
    "\n",
    "    # Build the correct exog row for that observed day\n",
    "    observed_idx = pd.DatetimeIndex([pd.to_datetime(OBSERVED_DATE)]).tz_localize(None).normalize()\n",
    "    observed_exog_row = build_future_exog(bundle, observed_idx).iloc[0].values.astype(float)\n",
    "\n",
    "    # Append + forecast next 3 days\n",
    "    pred_df = forecast_cgh_er_arrivals_next_3_days(\n",
    "        bundle,\n",
    "        observed_date=OBSERVED_DATE,\n",
    "        new_observed_arrivals=[float(arrivals_count)],\n",
    "        new_observed_exog=[observed_exog_row],      # correct exog row (NOT zeros)\n",
    "    )\n",
    "    print(f\"Observed arrivals for {OBSERVED_DATE}: {arrivals_count}\")\n",
    "    print(pred_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72542e8-63a5-47f1-8f87-aeba50c4a160",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cleanml310)",
   "language": "python",
   "name": "cleanml310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
